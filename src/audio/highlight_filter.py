"""
ì˜¤ë””ì˜¤ í•˜ì´ë¼ì´íŠ¸ í•„í„°ë§

RMS ì—ë„ˆì§€ì™€ Spectral íŠ¹ì„±ì„ ê²°í•©í•˜ì—¬ í•˜ì´ë¼ì´íŠ¸ êµ¬ê°„ ì¶”ì¶œ
"""

import librosa
import numpy as np
import subprocess
from pathlib import Path
from typing import List, Tuple, Optional
import time

from .audio_analyzer import (
    compute_rms_energy,
    compute_spectral_features,
    compute_combined_score,
    merge_segments,
    frames_to_time_segments
)


class AudioHighlightFilter:
    """
    ì˜¤ë””ì˜¤ ë¶„ì„ì„ í†µí•œ í•˜ì´ë¼ì´íŠ¸ êµ¬ê°„ í•„í„°ë§

    RMS ì—ë„ˆì§€(ìŒëŸ‰)ì™€ Spectral Centroid(ì£¼íŒŒìˆ˜)ë¥¼ ê²°í•©í•˜ì—¬
    ê²½ê¸° í•˜ì´ë¼ì´íŠ¸ êµ¬ê°„ì„ ìë™ìœ¼ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤.

    Args:
        threshold_percentile: ìƒìœ„ N% êµ¬ê°„ì„ í•˜ì´ë¼ì´íŠ¸ë¡œ ì„ íƒ (default: 60)
        merge_gap: ê°€ê¹Œìš´ êµ¬ê°„ì„ ë³‘í•©í•  ìµœëŒ€ ê°„ê²©(ì´ˆ) (default: 2.0)
        segment_duration: ê° í•˜ì´ë¼ì´íŠ¸ êµ¬ê°„ ê¸¸ì´(ì´ˆ) (default: 5.0)
        rms_weight: RMS ê°€ì¤‘ì¹˜ (default: 0.7)
        spectral_weight: Spectral ê°€ì¤‘ì¹˜ (default: 0.3)
        verbose: ì§„í–‰ ìƒí™© ì¶œë ¥ ì—¬ë¶€ (default: True)
    """

    def __init__(
        self,
        threshold_percentile: float = 60,
        merge_gap: float = 2.0,
        segment_duration: float = 5.0,
        rms_weight: float = 0.7,
        spectral_weight: float = 0.3,
        verbose: bool = True
    ):
        self.threshold_percentile = threshold_percentile
        self.merge_gap = merge_gap
        self.segment_duration = segment_duration
        self.rms_weight = rms_weight
        self.spectral_weight = spectral_weight
        self.verbose = verbose

    def _log(self, message: str):
        """ì§„í–‰ ìƒí™© ë¡œê·¸ ì¶œë ¥"""
        if self.verbose:
            print(message)

    def filter_audio(
        self,
        audio_path: str,
        sr: Optional[int] = None
    ) -> List[Tuple[float, float]]:
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ì—ì„œ í•˜ì´ë¼ì´íŠ¸ êµ¬ê°„ ì¶”ì¶œ

        Args:
            audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            sr: ìƒ˜í”Œë§ ë ˆì´íŠ¸ (Noneì´ë©´ ì›ë³¸ ìœ ì§€)

        Returns:
            [(start, end), ...] í˜•ì‹ì˜ í•˜ì´ë¼ì´íŠ¸ êµ¬ê°„ ë¦¬ìŠ¤íŠ¸
        """
        total_start = time.time()

        self._log("=" * 60)
        self._log("ğŸµ ì˜¤ë””ì˜¤ í•˜ì´ë¼ì´íŠ¸ í•„í„°ë§ ì‹œì‘")
        self._log("=" * 60)
        self._log(f"ğŸ“‚ ì…ë ¥ íŒŒì¼: {audio_path}")

        # Step 1: ì˜¤ë””ì˜¤ ë¡œë“œ
        step_start = time.time()
        self._log("\nğŸ”„ [1/4] ì˜¤ë””ì˜¤ ë¡œë“œ ì¤‘...")

        y, sr = librosa.load(audio_path, sr=sr)
        duration = len(y) / sr

        step_time = time.time() - step_start
        self._log(f"âœ… [1/4] ì˜¤ë””ì˜¤ ë¡œë“œ ì™„ë£Œ ({step_time:.2f}ì´ˆ)")
        self._log(f"   ğŸ“Š ìƒ˜í”Œë§ ë ˆì´íŠ¸: {sr} Hz")
        self._log(f"   â±ï¸  ì´ ê¸¸ì´: {duration:.2f}ì´ˆ ({duration/60:.1f}ë¶„)")

        # Step 2: RMS ì—ë„ˆì§€ ë¶„ì„
        step_start = time.time()
        self._log("\nğŸ”„ [2/4] RMS ì—ë„ˆì§€ ë¶„ì„ ì¤‘...")

        rms, times = compute_rms_energy(y, sr)

        step_time = time.time() - step_start
        self._log(f"âœ… [2/4] RMS ë¶„ì„ ì™„ë£Œ ({step_time:.2f}ì´ˆ)")
        self._log(f"   ğŸ“ˆ RMS í‰ê· : {np.mean(rms):.4f}")
        self._log(f"   ğŸ“ˆ RMS ìµœëŒ€: {np.max(rms):.4f}")

        # Step 3: Spectral íŠ¹ì„± ë¶„ì„
        step_start = time.time()
        self._log("\nğŸ”„ [3/4] Spectral íŠ¹ì„± ë¶„ì„ ì¤‘...")

        centroid, rolloff, zcr = compute_spectral_features(y, sr)

        step_time = time.time() - step_start
        self._log(f"âœ… [3/4] Spectral ë¶„ì„ ì™„ë£Œ ({step_time:.2f}ì´ˆ)")
        self._log(f"   ğŸ¼ Centroid í‰ê· : {np.mean(centroid):.2f} Hz")
        self._log(f"   ğŸ¼ Rolloff í‰ê· : {np.mean(rolloff):.2f} Hz")

        # Step 4: í•˜ì´ë¼ì´íŠ¸ êµ¬ê°„ ì¶”ì¶œ
        step_start = time.time()
        self._log("\nğŸ”„ [4/4] í•˜ì´ë¼ì´íŠ¸ êµ¬ê°„ ì¶”ì¶œ ì¤‘...")

        # ì¢…í•© ì ìˆ˜ ê³„ì‚°
        combined_score = compute_combined_score(
            rms, centroid,
            self.rms_weight, self.spectral_weight
        )

        # ì„ê³„ê°’ ê³„ì‚° (ìƒìœ„ N% êµ¬ê°„)
        threshold = np.percentile(combined_score, self.threshold_percentile)

        # ì„ê³„ê°’ ì´ìƒì¸ í”„ë ˆì„ ì°¾ê¸°
        highlight_frames = np.where(combined_score >= threshold)[0]

        if len(highlight_frames) == 0:
            self._log("âš ï¸  ê²½ê³ : í•˜ì´ë¼ì´íŠ¸ êµ¬ê°„ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            self._log("   ğŸ’¡ threshold_percentile ê°’ì„ ë‚®ì¶°ë³´ì„¸ìš”.")
            return []

        # í”„ë ˆì„ì„ ì‹œê°„ êµ¬ê°„ìœ¼ë¡œ ë³€í™˜
        segments = frames_to_time_segments(
            highlight_frames,
            sr=sr,
            hop_length=512,
            segment_duration=self.segment_duration
        )

        # ê°€ê¹Œìš´ êµ¬ê°„ ë³‘í•©
        merged_segments = merge_segments(segments, gap=self.merge_gap)

        # ì „ì²´ ê¸¸ì´ë¥¼ ë„˜ì§€ ì•Šë„ë¡ ì œí•œ
        final_segments = []
        for start, end in merged_segments:
            end = min(end, duration)
            if start < duration:
                final_segments.append((start, end))

        step_time = time.time() - step_start
        self._log(f"âœ… [4/4] êµ¬ê°„ ì¶”ì¶œ ì™„ë£Œ ({step_time:.2f}ì´ˆ)")
        self._log(f"   ğŸ¯ ì¶”ì¶œëœ êµ¬ê°„ ìˆ˜: {len(final_segments)}ê°œ")

        # í†µê³„ ì¶œë ¥
        total_highlight_duration = sum(end - start for start, end in final_segments)
        reduction_rate = (1 - total_highlight_duration / duration) * 100

        self._log(f"\nğŸ“Š í•„í„°ë§ ê²°ê³¼:")
        self._log(f"   â±ï¸  ì›ë³¸ ê¸¸ì´: {duration:.1f}ì´ˆ")
        self._log(f"   â±ï¸  í•„í„°ë§ í›„: {total_highlight_duration:.1f}ì´ˆ")
        self._log(f"   ğŸ“‰ ê°ì†Œìœ¨: {reduction_rate:.1f}%")

        total_time = time.time() - total_start
        self._log("\n" + "=" * 60)
        self._log(f"âœ¨ ì „ì²´ ì‘ì—… ì™„ë£Œ! (ì´ {total_time:.2f}ì´ˆ)")
        self._log("=" * 60)

        return final_segments

    def extract_audio_segments(
        self,
        audio_path: str,
        segments: List[Tuple[float, float]],
        output_dir: str = "output/audio_segments"
    ) -> List[str]:
        """
        FFmpegë¥¼ ì‚¬ìš©í•˜ì—¬ í•˜ì´ë¼ì´íŠ¸ êµ¬ê°„ë§Œ ì¶”ì¶œ

        Args:
            audio_path: ì›ë³¸ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            segments: [(start, end), ...] í˜•ì‹ì˜ êµ¬ê°„ ë¦¬ìŠ¤íŠ¸
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬

        Returns:
            ì¶”ì¶œëœ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        """
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        self._log(f"\nğŸ¬ ì˜¤ë””ì˜¤ êµ¬ê°„ ì¶”ì¶œ ì‹œì‘...")
        self._log(f"ğŸ“‚ ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")

        output_files = []

        for i, (start, end) in enumerate(segments, 1):
            output_file = output_path / f"segment_{i:03d}.mp3"

            self._log(f"   [{i}/{len(segments)}] {start:.1f}ì´ˆ ~ {end:.1f}ì´ˆ ì¶”ì¶œ ì¤‘...")

            # FFmpeg ëª…ë ¹ì–´
            cmd = [
                "ffmpeg",
                "-i", str(audio_path),
                "-ss", str(start),
                "-to", str(end),
                "-c:a", "libmp3lame",  # MP3 ì¸ì½”ë”
                "-q:a", "2",  # ê³ í’ˆì§ˆ
                "-y",  # ë®ì–´ì“°ê¸°
                str(output_file)
            ]

            try:
                subprocess.run(
                    cmd,
                    check=True,
                    capture_output=True,
                    text=True
                )
                output_files.append(str(output_file))
            except subprocess.CalledProcessError as e:
                self._log(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e.stderr}")
                continue

        self._log(f"âœ… ì´ {len(output_files)}ê°œ êµ¬ê°„ ì¶”ì¶œ ì™„ë£Œ!")

        return output_files


def filter_highlight_segments(
    audio_path: str,
    threshold_percentile: float = 60,
    merge_gap: float = 2.0,
    segment_duration: float = 5.0,
    verbose: bool = True
) -> List[Tuple[float, float]]:
    """
    í¸ì˜ í•¨ìˆ˜: ì˜¤ë””ì˜¤ í•˜ì´ë¼ì´íŠ¸ êµ¬ê°„ ì¶”ì¶œ

    Args:
        audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        threshold_percentile: ìƒìœ„ N% êµ¬ê°„ ì„ íƒ (default: 60)
        merge_gap: êµ¬ê°„ ë³‘í•© ìµœëŒ€ ê°„ê²©(ì´ˆ) (default: 2.0)
        segment_duration: ê° êµ¬ê°„ ê¸¸ì´(ì´ˆ) (default: 5.0)
        verbose: ì§„í–‰ ìƒí™© ì¶œë ¥ ì—¬ë¶€ (default: True)

    Returns:
        [(start, end), ...] í˜•ì‹ì˜ í•˜ì´ë¼ì´íŠ¸ êµ¬ê°„ ë¦¬ìŠ¤íŠ¸
    """
    filter = AudioHighlightFilter(
        threshold_percentile=threshold_percentile,
        merge_gap=merge_gap,
        segment_duration=segment_duration,
        verbose=verbose
    )

    return filter.filter_audio(audio_path)


if __name__ == "__main__":
    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
    import sys

    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python highlight_filter.py <audio_file>")
        sys.exit(1)

    audio_path = sys.argv[1]

    # í•˜ì´ë¼ì´íŠ¸ êµ¬ê°„ ì¶”ì¶œ
    segments = filter_highlight_segments(audio_path)

    print(f"\nì¶”ì¶œëœ í•˜ì´ë¼ì´íŠ¸ êµ¬ê°„:")
    for i, (start, end) in enumerate(segments, 1):
        print(f"  {i}. {start:.1f}ì´ˆ ~ {end:.1f}ì´ˆ (ê¸¸ì´: {end-start:.1f}ì´ˆ)")
