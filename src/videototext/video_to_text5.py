import os
import ffmpeg
from faster_whisper import WhisperModel
import torch
import time
from pydub import AudioSegment, effects
from pydub.silence import split_on_silence

# ---------- ì‚¬ìš©ì ì„¤ì • ----------
VIDEO_PATH = "match.mp4"
AUDIO_FILE_WAV = "temp_audio.wav"
CLEAN_AUDIO_DIR = "clean_chunks"
OUTPUT_TXT = "match_transcript.txt"

MODEL_SIZE = "tiny"   # tiny/base
LANG = "ko"

MIN_SILENCE_LEN = 1000
SILENCE_THRESH = -35
KEEP_SILENCE = 500
# ----------------------------------


def extract_audio(video_path, audio_path):
    """ffmpegë¡œ ì˜ìƒì—ì„œ ì˜¤ë””ì˜¤ ì¶”ì¶œ (16kHz, ëª¨ë…¸, PCM)"""
    print(f"ğŸ§ ì˜¤ë””ì˜¤ ì¶”ì¶œ: {video_path}")
    (
        ffmpeg
        .input(video_path)
        .output(audio_path, ac=1, ar=16000, acodec="pcm_s16le")
        .overwrite_output()
        .run(quiet=False)
    )
    print(f"âœ… ì˜¤ë””ì˜¤ ì¶”ì¶œ ì™„ë£Œ â†’ {audio_path}")


def split_and_clean_audio(audio_path, output_dir,
                          min_silence_len, silence_thresh, keep_silence):
    """ì˜¤ë””ì˜¤ë¥¼ ì¹¨ë¬µ ê¸°ì¤€ìœ¼ë¡œ ì²­í¬ ë¶„ë¦¬ í›„ normalize"""
    print(f"\nğŸ”‡ ì¹¨ë¬µ ê¸°ì¤€ ì²­í¬ ë¶„ë¦¬: {audio_path}")
    audio = AudioSegment.from_wav(audio_path)
    audio = effects.normalize(audio)

    avg_db = audio.dBFS
    adjusted_thresh = silence_thresh if avg_db < silence_thresh else avg_db - 10
    print(f"í‰ê·  ë³¼ë¥¨: {avg_db:.1f} dBFS â†’ ì„ê³„ê°’: {adjusted_thresh:.1f} dBFS")

    chunks = split_on_silence(audio,
                              min_silence_len=min_silence_len,
                              silence_thresh=adjusted_thresh,
                              keep_silence=keep_silence)

    if not chunks:
        raise Exception("âŒ ë°œí™” êµ¬ê°„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. SILENCE_THRESH ì¡°ì • í•„ìš”")

    os.makedirs(output_dir, exist_ok=True)
    chunk_paths = []

    for i, chunk in enumerate(chunks):
        path = os.path.join(output_dir, f"chunk_{i}.wav")
        chunk.export(path, format="wav")
        chunk_paths.append(path)

    print(f"âœ… ì´ {len(chunks)}ê°œ ì²­í¬ ìƒì„± â†’ {output_dir}")
    return chunk_paths


def transcribe_chunks_merge_text(chunk_paths, output_txt, model_size, lang):
    """ì²­í¬ë³„ Whisper ë³€í™˜ í›„ í…ìŠ¤íŠ¸ ë³‘í•©"""
    device = "cuda" if torch.cuda.is_available() else "cpu"
    compute_type = "float16" if device == "cuda" else "int8"

    print(f"\nâš™ï¸ Whisper ëª¨ë¸ ë¡œë“œ: {model_size}, {device}, {compute_type}")
    model = WhisperModel(model_size, device=device, compute_type=compute_type)

    all_text = []
    start_time = time.perf_counter()

    for i, path in enumerate(chunk_paths):
        print(f"â–¶ï¸ ë³€í™˜ ì¤‘: ì²­í¬ {i + 1}/{len(chunk_paths)} â†’ {path}")
        segments, _ = model.transcribe(path, beam_size=5, language=lang)
        for seg in segments:
            # íƒ€ì„ìŠ¤íƒ¬í”„ ì—†ì´ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë§Œ ì¶”ê°€
            text = seg.text.strip()
            if text:  # ë¹ˆ í…ìŠ¤íŠ¸ ì œì™¸
                all_text.append(text)

    # ê²°ê³¼ë¥¼ í•œ ì¤„ë¡œ ì´ì–´ì„œ íŒŒì¼ ì €ì¥
    full_text = " ".join(all_text)
    with open(output_txt, "w", encoding="utf-8") as f:
        f.write(full_text)

    elapsed = time.perf_counter() - start_time
    print(f"\nâœ… ì „ì²´ ë³€í™˜ ì™„ë£Œ â†’ {os.path.abspath(output_txt)}")
    print(f"ì´ ì†Œìš” ì‹œê°„: {elapsed:.1f}ì´ˆ")


if __name__ == "__main__":
    try:
        # 1ï¸âƒ£ ì˜¤ë””ì˜¤ ì¶”ì¶œ
        extract_audio(VIDEO_PATH, AUDIO_FILE_WAV)

        # 2ï¸âƒ£ ì²­í¬ ë‹¨ìœ„ ë¶„ë¦¬ ë° ì €ì¥
        chunk_paths = split_and_clean_audio(AUDIO_FILE_WAV, CLEAN_AUDIO_DIR,
                                            MIN_SILENCE_LEN, SILENCE_THRESH, KEEP_SILENCE)

        # 3ï¸âƒ£ ì²­í¬ë³„ ë³€í™˜ + ìˆœìˆ˜ í…ìŠ¤íŠ¸ ë³‘í•©
        transcribe_chunks_merge_text(chunk_paths, OUTPUT_TXT, MODEL_SIZE, LANG)

    except Exception as e:
        print(f"\nğŸš¨ ì˜¤ë¥˜ ë°œìƒ: {e}")

    finally:
        # 4ï¸âƒ£ ì„ì‹œ íŒŒì¼ ì •ë¦¬
        try:
            if os.path.exists(AUDIO_FILE_WAV):
                os.remove(AUDIO_FILE_WAV)
            # ì²­í¬ í´ë”ëŠ” í™•ì¸ í›„ ì‚­ì œ ê°€ëŠ¥
        except OSError as e:
            print(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ ì˜¤ë¥˜: {e}")
