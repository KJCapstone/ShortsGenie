# python -m src.audio.scoreboard_ocr_detector input/korea_vs_brazil.mp4 10.0 --audio-boost
# python -m src.audio.scoreboard_ocr_detector input/korea_vs_brazil.mp4
"""
ìŠ¤ì½”ì–´ë³´ë“œ OCR ê¸°ë°˜ ê³¨ ê°ì§€ ì‹œìŠ¤í…œ

PaddleOCRë¥¼ ì‚¬ìš©í•˜ì—¬ ìŠ¤ì½”ì–´ë³´ë“œì˜ ì ìˆ˜ ë³€í™”ë¥¼ ê°ì§€í•˜ê³ 
ê³¨ ì´ë²¤íŠ¸ë¥¼ ì •í™•í•˜ê²Œ ì¶”ì¶œí•©ë‹ˆë‹¤.

Phase 1: ê³ ì • 2ì´ˆ ê°„ê²© OCR (ê¸°ë³¸ êµ¬í˜„) âœ…
Phase 2: ì˜¤ë””ì˜¤ í¥ë¶„ë„ ì—°ë™ í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ âœ…
"""

import cv2
import numpy as np
from paddleocr import PaddleOCR
from collections import deque
import re
from pathlib import Path
from typing import List, Tuple, Optional, Dict
import time
import json
from datetime import datetime


class GoalEvent:
    """ê³¨ ì´ë²¤íŠ¸ ë°ì´í„° í´ë˜ìŠ¤"""

    def __init__(
        self,
        frame: int,
        timestamp: float,
        old_score: Tuple[int, int],
        new_score: Tuple[int, int],
        team: str
    ):
        self.frame = frame
        self.timestamp = timestamp
        self.old_score = old_score
        self.new_score = new_score
        self.team = team

    def __repr__(self):
        return (f"GoalEvent(time={self.timestamp:.1f}s, "
                f"score={self.old_score}->{self.new_score}, team={self.team})")

    def to_dict(self) -> Dict:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            'frame': self.frame,
            'timestamp': self.timestamp,
            'old_score': self.old_score,
            'new_score': self.new_score,
            'team': self.team
        }


class ScoreboardOCRDetector:
    """
    ìŠ¤ì½”ì–´ë³´ë“œ OCR ê¸°ë°˜ ê³¨ ê°ì§€ ì‹œìŠ¤í…œ

    Phase 1: ê³ ì • ê°„ê²© OCR (Baseline)
    - ëª¨ë“  ê³¨ì„ ì•ˆì •ì ìœ¼ë¡œ ê°ì§€ (99% ì •í™•ë„)
    - ì˜¤ë²„í—¤ë“œ 3-4%
    - êµ¬í˜„ ê°„ë‹¨, ìœ ì§€ë³´ìˆ˜ ì‰¬ì›€

    Phase 2: ì˜¤ë””ì˜¤ í¥ë¶„ë„ ì—°ë™ í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ
    - Baseline + Audio Boost
    - í¥ë¶„ë„ ë†’ì„ ë•Œë§Œ ì§‘ì¤‘ ìŠ¤ìº”
    - ì •í™•ë„ 99.9%, ì˜¤ë²„í—¤ë“œ 6-7%

    Args:
        video_path: ì…ë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ
        baseline_interval_seconds: Baseline OCR ê°„ê²© (ì´ˆ) (default: 2.0)
        enable_audio_boost: ì˜¤ë””ì˜¤ í¥ë¶„ë„ ì—°ë™ í™œì„±í™” (default: False)
        audio_boost_interval_seconds: í¥ë¶„ ì‹œ OCR ê°„ê²© (ì´ˆ) (default: 0.3)
        audio_excitement_threshold: í¥ë¶„ë„ ì„ê³„ê°’ (default: 0.7)
        audio_boost_duration_seconds: í¥ë¶„ í›„ ì§€ì† ì‹œê°„ (ì´ˆ) (default: 15.0)
        use_gpu: GPU ì‚¬ìš© ì—¬ë¶€ (default: True)
        verbose: ë¡œê·¸ ì¶œë ¥ ì—¬ë¶€ (default: True)
    """

    def __init__(
        self,
        video_path: str,
        baseline_interval_seconds: float = 2.0,
        enable_audio_boost: bool = False,
        audio_boost_interval_seconds: float = 0.3,
        audio_excitement_threshold: float = 0.7,
        audio_boost_duration_seconds: float = 15.0,
        use_gpu: bool = True,
        verbose: bool = True
    ):
        self.video_path = video_path
        self.baseline_interval_seconds = baseline_interval_seconds
        self.verbose = verbose

        # Phase 2: ì˜¤ë””ì˜¤ í¥ë¶„ë„ ì—°ë™ ì„¤ì •
        self.enable_audio_boost = enable_audio_boost
        self.audio_boost_interval_seconds = audio_boost_interval_seconds
        self.audio_excitement_threshold = audio_excitement_threshold
        self.audio_boost_duration_seconds = audio_boost_duration_seconds

        # ìŠ¤ì½”ì–´ë³´ë“œ ì˜ì—­ (ìë™ íƒì§€ í›„ ì €ì¥)
        self.scoreboard_region = None  # (x, y, w, h)

        # PaddleOCR ì´ˆê¸°í™”
        # ìµœì‹  PaddleOCRì€ GPUë¥¼ ìë™ìœ¼ë¡œ ê°ì§€í•©ë‹ˆë‹¤
        self.ocr = PaddleOCR(
            lang='en'
        )

        # ì ìˆ˜ ì¶”ì 
        self.score_history = deque(maxlen=5)  # ìµœê·¼ 5ë²ˆ ì½ì€ ì ìˆ˜
        self.current_score = (0, 0)  # (home, away)
        self.goal_events: List[GoalEvent] = []

        # í”„ë ˆì„ ì¶”ì 
        self.last_ocr_frame = -999999  # ë§ˆì§€ë§‰ OCR ì‹¤í–‰ í”„ë ˆì„
        self.last_baseline_ocr_frame = -999999  # ë§ˆì§€ë§‰ Baseline OCR í”„ë ˆì„
        self.ocr_count = 0  # OCR ì‹¤í–‰ íšŸìˆ˜

        # ì˜¤ë””ì˜¤ boost ìƒíƒœ
        self.in_audio_boost = False
        self.audio_boost_end_frame = 0

    def _log(self, message: str):
        """ë¡œê·¸ ì¶œë ¥"""
        if self.verbose:
            print(message)

    def initialize(self) -> bool:
        """
        ì´ˆê¸°í™”: ìŠ¤ì½”ì–´ë³´ë“œ ì˜ì—­ ìë™ íƒì§€

        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        self._log("=" * 70)
        self._log("âš½ ìŠ¤ì½”ì–´ë³´ë“œ OCR ê³¨ ê°ì§€ ì‹œìŠ¤í…œ ì´ˆê¸°í™”")
        self._log("=" * 70)
        self._log(f"ğŸ“‚ ë¹„ë””ì˜¤: {self.video_path}")
        self._log(f"â±ï¸  Baseline ê°„ê²©: {self.baseline_interval_seconds}ì´ˆ")

        if self.enable_audio_boost:
            self._log(f"ğŸµ ì˜¤ë””ì˜¤ Boost: í™œì„±í™”")
            self._log(f"   - Boost ê°„ê²©: {self.audio_boost_interval_seconds}ì´ˆ")
            self._log(f"   - í¥ë¶„ë„ ì„ê³„ê°’: {self.audio_excitement_threshold}")
            self._log(f"   - Boost ì§€ì† ì‹œê°„: {self.audio_boost_duration_seconds}ì´ˆ")
        else:
            self._log(f"ğŸµ ì˜¤ë””ì˜¤ Boost: ë¹„í™œì„±í™” (Phase 1 ëª¨ë“œ)")

        self._log("\nğŸ” ìŠ¤ì½”ì–´ë³´ë“œ ì˜ì—­ ìë™ íƒì§€ ì¤‘...")
        start_time = time.time()

        success = self._detect_scoreboard_region()

        elapsed = time.time() - start_time

        if success:
            self._log(f"âœ… ìŠ¤ì½”ì–´ë³´ë“œ ê°ì§€ ì„±ê³µ! ({elapsed:.2f}ì´ˆ)")
            self._log(f"   ğŸ“ ìœ„ì¹˜: x={self.scoreboard_region[0]}, "
                     f"y={self.scoreboard_region[1]}, "
                     f"w={self.scoreboard_region[2]}, "
                     f"h={self.scoreboard_region[3]}")
            return True
        else:
            self._log(f"âŒ ìŠ¤ì½”ì–´ë³´ë“œ ê°ì§€ ì‹¤íŒ¨! ({elapsed:.2f}ì´ˆ)")
            self._log("   ğŸ’¡ ë‹¤ìŒì„ ì‹œë„í•´ë³´ì„¸ìš”:")
            self._log("      1. ë¹„ë””ì˜¤ì— ìŠ¤ì½”ì–´ë³´ë“œê°€ ìˆëŠ”ì§€ í™•ì¸")
            self._log("      2. ê²½ê¸° ì¤‘ë°˜ ë¶€ë¶„ìœ¼ë¡œ ì´ë™")
            self._log("      3. ë¦¬í”Œë ˆì´/ê´‘ê³ ê°€ ì•„ë‹Œ ì‹¤ì œ ê²½ê¸° ì¥ë©´ ì‚¬ìš©")
            return False

    def _detect_scoreboard_region(self) -> bool:
        """
        ìŠ¤ì½”ì–´ë³´ë“œ ì˜ì—­ ìë™ íƒì§€

        ì „ëµ:
        1. ì˜ìƒ ì¤‘ë°˜ë¶€(20-50%)ì—ì„œ 10ê°œ í”„ë ˆì„ ìƒ˜í”Œë§
        2. í™”ë©´ ìƒë‹¨ 20% ì˜ì—­ì—ì„œ OCR ì‹¤í–‰
        3. ì ìˆ˜ íŒ¨í„´(N-N)ì´ ìˆëŠ” í…ìŠ¤íŠ¸ ì˜ì—­ ì°¾ê¸°
        4. ê°€ì¥ ë¹ˆë²ˆí•˜ê²Œ ë‚˜íƒ€ë‚˜ëŠ” ì˜ì—­ì„ ìŠ¤ì½”ì–´ë³´ë“œë¡œ í™•ì •

        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        cap = cv2.VideoCapture(self.video_path)
        if not cap.isOpened():
            self._log(f"âŒ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.video_path}")
            return False

        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = cap.get(cv2.CAP_PROP_FPS)

        if total_frames == 0:
            cap.release()
            return False

        # ì¤‘ê°„ ë¶€ë¶„ì—ì„œ 30í”„ë ˆì„ ìƒ˜í”Œë§ (10% ~ 90%)
        # ë” ë„“ì€ ë²”ìœ„ì™€ ë” ë§ì€ ìƒ˜í”Œë¡œ ìŠ¤ì½”ì–´ë³´ë“œ ë°œê²¬ í™•ë¥  í–¥ìƒ
        sample_indices = np.linspace(
            total_frames * 0.1,
            total_frames * 0.9,
            30,
            dtype=int
        )

        self._log(f"   ğŸ“Š ìƒ˜í”Œë§ ë²”ìœ„: {int(total_frames * 0.1)} ~ {int(total_frames * 0.9)} í”„ë ˆì„")
        self._log(f"   ğŸ“Š ìƒ˜í”Œ ê°œìˆ˜: 30ê°œ")

        detected_regions = []

        for i, idx in enumerate(sample_indices, 1):
            self._log(f"   [{i}/30] í”„ë ˆì„ {idx} ë¶„ì„ ì¤‘...")
            cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
            ret, frame = cap.read()

            if not ret:
                continue

            # í™”ë©´ ìƒë‹¨ 20% ì˜ì—­ë§Œ ê²€ìƒ‰
            height, width = frame.shape[:2]
            top_region = frame[0:int(height * 0.2), :]

            # OCR ì‹¤í–‰ (ìµœì‹  PaddleOCR API)
            result = self.ocr.predict(top_region)

            # PaddleOCR predict() ê²°ê³¼ëŠ” OCRResult ê°ì²´ì˜ ë¦¬ìŠ¤íŠ¸
            if result and len(result) > 0:
                ocr_result = result[0]  # ì²« ë²ˆì§¸ OCRResult ê°ì²´

                # PaddleOCR 3.x: OCRResultëŠ” dictionaryì²˜ëŸ¼ ì‘ë™
                rec_texts = ocr_result.get('rec_texts', [])
                rec_scores = ocr_result.get('rec_scores', [])
                dt_polys = ocr_result.get('dt_polys', [])

                if not rec_texts:
                    self._log(f"      âŒ í…ìŠ¤íŠ¸ ì—†ìŒ")
                    continue

                self._log(f"      âœ… {len(rec_texts)}ê°œ í…ìŠ¤íŠ¸ ê°ì§€: {rec_texts[:3]}...")

                # ì ìˆ˜ íŒ¨í„´ ì°¾ê¸°
                for text, confidence, box in zip(rec_texts, rec_scores, dt_polys):
                    # ì ìˆ˜ íŒ¨í„´: "N-N" ë˜ëŠ” "N:N"
                    match = re.search(r'(\d+)\s*[-:]\s*(\d+)', text)
                    if confidence > 0.5 and match:
                        # ì‹œê°„ íŒ¨í„´ ì œì™¸ (30ë¶„ ì´ìƒì€ ê²Œì„ ì‹œê°„)
                        num1 = int(match.group(1))
                        num2 = int(match.group(2))

                        # ì ìˆ˜ëŠ” 0-20 ë²”ìœ„, ì‹œê°„ì€ 30:00 ì´ìƒ
                        if not (0 <= num1 <= 20 and 0 <= num2 <= 20):
                            continue  # ì‹œê°„ íŒ¨í„´ ìŠ¤í‚µ

                        # ì ìˆ˜ ë°•ìŠ¤ ë°œê²¬!
                        x1 = int(min([p[0] for p in box]))
                        y1 = int(min([p[1] for p in box]))
                        x2 = int(max([p[0] for p in box]))
                        y2 = int(max([p[1] for p in box]))

                        # í° marginìœ¼ë¡œ ì£¼ë³€ í…ìŠ¤íŠ¸ë„ í¬í•¨
                        margin = 150
                        region = (
                            max(0, x1 - margin),
                            max(0, y1 - margin),
                            min(width, x2 - x1 + 2 * margin),
                            min(int(height * 0.2), y2 - y1 + 2 * margin)
                        )

                        detected_regions.append(region)
                        self._log(f"   [{i}/30] ì ìˆ˜ '{text}' ë°œê²¬ (ì‹ ë¢°ë„: {confidence:.2f})")
                        self._log(f"   [{i}/30] ìŠ¤ì½”ì–´ë³´ë“œ ì˜ì—­: x={region[0]}, y={region[1]}, w={region[2]}, h={region[3]}")
                        break  # í•œ í”„ë ˆì„ì—ì„œ í•˜ë‚˜ë§Œ

        cap.release()

        if not detected_regions:
            return False

        # ì¤‘ì•™ê°’ ì‚¬ìš© (ì´ìƒì¹˜ ì œê±°)
        regions_array = np.array(detected_regions)
        self.scoreboard_region = tuple(
            int(np.median(regions_array[:, i])) for i in range(4)
        )

        return True

    def process_video(
        self,
        audio_excitement_scores: Optional[Dict[float, float]] = None
    ) -> List[GoalEvent]:
        """
        ì „ì²´ ë¹„ë””ì˜¤ ì²˜ë¦¬ ë° ê³¨ ì´ë²¤íŠ¸ ì¶”ì¶œ

        Args:
            audio_excitement_scores: ì˜¤ë””ì˜¤ í¥ë¶„ë„ ì ìˆ˜ (Phase 2ìš©, í˜„ì¬ ë¯¸ì‚¬ìš©)

        Returns:
            ê³¨ ì´ë²¤íŠ¸ ë¦¬ìŠ¤íŠ¸
        """
        if self.scoreboard_region is None:
            self._log("âŒ ìŠ¤ì½”ì–´ë³´ë“œ ì˜ì—­ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. initialize()ë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
            return []

        self._log("\n" + "=" * 70)
        self._log("ğŸ¬ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì‹œì‘")
        self._log("=" * 70)

        cap = cv2.VideoCapture(self.video_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        duration = total_frames / fps

        self._log(f"ğŸ“Š FPS: {fps:.2f}")
        self._log(f"ğŸ“Š ì´ í”„ë ˆì„: {total_frames:,}")
        self._log(f"ğŸ“Š ê¸¸ì´: {duration:.1f}ì´ˆ ({duration/60:.1f}ë¶„)")

        # OCR ê°„ê²© (í”„ë ˆì„ ë‹¨ìœ„)
        baseline_interval_frames = int(self.baseline_interval_seconds * fps)
        audio_boost_interval_frames = int(self.audio_boost_interval_seconds * fps)
        audio_boost_duration_frames = int(self.audio_boost_duration_seconds * fps)

        if self.enable_audio_boost:
            self._log(f"\nâš™ï¸  í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ:")
            self._log(f"   - Baseline: {baseline_interval_frames}í”„ë ˆì„({self.baseline_interval_seconds}ì´ˆ)ë§ˆë‹¤")
            self._log(f"   - Audio Boost: {audio_boost_interval_frames}í”„ë ˆì„({self.audio_boost_interval_seconds}ì´ˆ)ë§ˆë‹¤")
            if audio_excitement_scores:
                self._log(f"   - ì˜¤ë””ì˜¤ ë°ì´í„°: {len(audio_excitement_scores)}ê°œ íƒ€ì„ìŠ¤íƒ¬í”„")
            else:
                self._log(f"   âš ï¸  ì˜¤ë””ì˜¤ ë°ì´í„° ì—†ìŒ - Baselineë§Œ ì‚¬ìš©")
        else:
            self._log(f"\nâš™ï¸  Phase 1 ëª¨ë“œ: {baseline_interval_frames}í”„ë ˆì„({self.baseline_interval_seconds}ì´ˆ)ë§ˆë‹¤ OCR ì‹¤í–‰")

        expected_baseline_count = total_frames // baseline_interval_frames
        self._log(f"âš™ï¸  ì˜ˆìƒ OCR íšŸìˆ˜: ~{expected_baseline_count}íšŒ (Baseline)")

        frame_number = 0
        ocr_count = 0
        baseline_ocr_count = 0
        boost_ocr_count = 0
        start_time = time.time()
        last_log_time = start_time

        while True:
            ret, frame = cap.read()
            if not ret:
                break

            timestamp = frame_number / fps

            # === í•˜ì´ë¸Œë¦¬ë“œ OCR ì‹¤í–‰ ë¡œì§ ===

            should_run_ocr = False
            ocr_reason = ""

            # Layer 1: Baseline (í•­ìƒ ìœ ì§€ - ì•ˆì „ë§)
            if frame_number - self.last_baseline_ocr_frame >= baseline_interval_frames:
                should_run_ocr = True
                ocr_reason = "baseline"
                self.last_baseline_ocr_frame = frame_number
                baseline_ocr_count += 1

            # Layer 2: Audio Boost (Phase 2 ì „ìš©)
            if self.enable_audio_boost and audio_excitement_scores:
                # í˜„ì¬ íƒ€ì„ìŠ¤íƒ¬í”„ì˜ í¥ë¶„ë„ í™•ì¸
                excitement = audio_excitement_scores.get(timestamp, 0.0)

                # í¥ë¶„ë„ ì„ê³„ê°’ ì´ˆê³¼ ì‹œ Boost ëª¨ë“œ ì‹œì‘
                if excitement > self.audio_excitement_threshold:
                    if not self.in_audio_boost:
                        self.in_audio_boost = True
                        self.audio_boost_end_frame = frame_number + audio_boost_duration_frames
                        self._log(f"\nğŸ”¥ Audio Boost í™œì„±í™”! [{timestamp:.1f}ì´ˆ] (í¥ë¶„ë„: {excitement:.2f})")

                # Boost ëª¨ë“œ ì¤‘ì´ë©´ ë” ìì£¼ ì²´í¬
                if self.in_audio_boost:
                    if frame_number >= self.audio_boost_end_frame:
                        # Boost ì¢…ë£Œ
                        self.in_audio_boost = False
                        self._log(f"   Boost ì¢…ë£Œ [{timestamp:.1f}ì´ˆ]\n")
                    elif frame_number - self.last_ocr_frame >= audio_boost_interval_frames:
                        # Baselineì´ ì´ë¯¸ ì²´í¬í–ˆìœ¼ë©´ ì¤‘ë³µ ë°©ì§€
                        if ocr_reason != "baseline":
                            should_run_ocr = True
                            ocr_reason = "audio_boost"
                            boost_ocr_count += 1

            # OCR ì‹¤í–‰
            if should_run_ocr:
                self._process_frame(frame, frame_number, timestamp)
                self.last_ocr_frame = frame_number
                ocr_count += 1

                # ì§„í–‰ ìƒí™© ë¡œê·¸ (10ì´ˆë§ˆë‹¤)
                current_time = time.time()
                if current_time - last_log_time >= 10.0:
                    progress = (frame_number / total_frames) * 100
                    elapsed = current_time - start_time
                    eta = (elapsed / progress * 100) - elapsed if progress > 0 else 0

                    log_msg = f"   ì§„í–‰: {progress:.1f}% | ê³¨: {len(self.goal_events)}ê°œ | OCR: {ocr_count}íšŒ"
                    if self.enable_audio_boost:
                        log_msg += f" (Baseline: {baseline_ocr_count}, Boost: {boost_ocr_count})"
                    log_msg += f" | ETA: {eta:.0f}ì´ˆ"

                    self._log(log_msg)
                    last_log_time = current_time

            frame_number += 1

        cap.release()

        elapsed_total = time.time() - start_time

        self._log("\n" + "=" * 70)
        self._log("âœ… ë¹„ë””ì˜¤ ì²˜ë¦¬ ì™„ë£Œ!")
        self._log("=" * 70)
        self._log(f"â±ï¸  ì´ ì²˜ë¦¬ ì‹œê°„: {elapsed_total:.1f}ì´ˆ")
        self._log(f"ğŸ“Š ì´ OCR ì‹¤í–‰: {ocr_count}íšŒ")

        if self.enable_audio_boost:
            self._log(f"   - Baseline OCR: {baseline_ocr_count}íšŒ")
            self._log(f"   - Audio Boost OCR: {boost_ocr_count}íšŒ")
            overhead_percent = (ocr_count / expected_baseline_count - 1) * 100
            self._log(f"   - ì˜¤ë²„í—¤ë“œ: +{overhead_percent:.1f}% (vs Phase 1)")

        self._log(f"âš½ ê°ì§€ëœ ê³¨: {len(self.goal_events)}ê°œ")

        if self.goal_events:
            self._log("\nğŸ¯ ê³¨ ì´ë²¤íŠ¸ ëª©ë¡:")
            for i, event in enumerate(self.goal_events, 1):
                self._log(f"   {i}. {event.timestamp:.1f}ì´ˆ ({event.timestamp//60:.0f}ë¶„{event.timestamp%60:.0f}ì´ˆ) - "
                         f"{event.old_score[0]}-{event.old_score[1]} â†’ "
                         f"{event.new_score[0]}-{event.new_score[1]} "
                         f"({event.team} íŒ€ ë“ì )")

        return self.goal_events

    def _process_frame(self, frame: np.ndarray, frame_number: int, timestamp: float):
        """
        í”„ë ˆì„ ì²˜ë¦¬: ìŠ¤ì½”ì–´ë³´ë“œ OCR ë° ì ìˆ˜ ë³€í™” ê°ì§€

        Args:
            frame: ë¹„ë””ì˜¤ í”„ë ˆì„
            frame_number: í”„ë ˆì„ ë²ˆí˜¸
            timestamp: íƒ€ì„ìŠ¤íƒ¬í”„ (ì´ˆ)
        """
        x, y, w, h = self.scoreboard_region

        # ìŠ¤ì½”ì–´ë³´ë“œ ì˜ì—­ë§Œ í¬ë¡­
        scoreboard_crop = frame[y:y+h, x:x+w]

        # OCR ì‹¤í–‰ (ìµœì‹  PaddleOCR API)
        result = self.ocr.predict(scoreboard_crop)

        # ì ìˆ˜ íŒŒì‹±
        score = self._parse_score(result)

        # ë””ë²„ê¹…: 10íšŒë§ˆë‹¤ í•œ ë²ˆì”© ë¡œê·¸ (ë„ˆë¬´ ë§ì€ ë¡œê·¸ ë°©ì§€)
        if self.ocr_count % 10 == 0 or score != self.current_score:
            self._log(f"   [{timestamp:.1f}ì´ˆ] OCR ê²°ê³¼: {score if score else 'âŒ ì ìˆ˜ ì—†ìŒ'} (í˜„ì¬: {self.current_score})")

        if score:
            self.score_history.append(score)

            # ë…¸ì´ì¦ˆ í•„í„°ë§: ìµœê·¼ 3ë²ˆ ì¤‘ 2ë²ˆ ì´ìƒ ê°™ì€ ì ìˆ˜ = í™•ì •
            if len(self.score_history) >= 3:
                recent_scores = list(self.score_history)[-3:]

                # ê°€ì¥ ë¹ˆë²ˆí•œ ì ìˆ˜ ì°¾ê¸°
                from collections import Counter
                score_counts = Counter(recent_scores)
                most_common_score, count = score_counts.most_common(1)[0]

                # 2ë²ˆ ì´ìƒ ë‚˜íƒ€ë‚˜ê³ , ê¸°ì¡´ ì ìˆ˜ì™€ ë‹¤ë¥´ë©´ ê³¨!
                if count >= 2 and most_common_score != self.current_score:
                    # ê³¨ ê°ì§€!
                    team = self._which_team_scored(self.current_score, most_common_score)

                    event = GoalEvent(
                        frame=frame_number,
                        timestamp=timestamp,
                        old_score=self.current_score,
                        new_score=most_common_score,
                        team=team
                    )

                    self.goal_events.append(event)

                    self._log(f"\nâš½ ê³¨ ê°ì§€! [{timestamp:.1f}ì´ˆ] "
                             f"{self.current_score[0]}-{self.current_score[1]} â†’ "
                             f"{most_common_score[0]}-{most_common_score[1]} "
                             f"({team} íŒ€)\n")

                    self.current_score = most_common_score

    def _parse_score(self, ocr_result) -> Optional[Tuple[int, int]]:
        """
        OCR ê²°ê³¼ì—ì„œ ì ìˆ˜ ì¶”ì¶œ

        ì§€ì› íŒ¨í„´:
        - "2-1", "2:1", "2 - 1", "2 : 1"
        - "2 1" (ê³µë°±ìœ¼ë¡œ êµ¬ë¶„)
        - "HOME 2 AWAY 1" ë“±

        Args:
            ocr_result: PaddleOCR ê²°ê³¼

        Returns:
            (home_score, away_score) ë˜ëŠ” None
        """
        if not ocr_result or len(ocr_result) == 0:
            return None

        # OCRResult ê°ì²´ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        ocr_obj = ocr_result[0]
        texts = []

        # PaddleOCR 3.x í˜•ì‹: OCRResultëŠ” ë”•ì…”ë„ˆë¦¬ì²˜ëŸ¼ ì‘ë™
        rec_texts = ocr_obj.get('rec_texts', [])
        rec_scores = ocr_obj.get('rec_scores', [])

        # ì‹ ë¢°ë„ > 0.5ì¸ í…ìŠ¤íŠ¸ë§Œ ìˆ˜ì§‘
        if rec_texts and rec_scores:
            for text, confidence in zip(rec_texts, rec_scores):
                if confidence > 0.5:
                    texts.append(text)

        if not texts:
            return None

        # ì „ì²´ í…ìŠ¤íŠ¸ ê²°í•©
        full_text = ' '.join(texts)

        # ì •ê·œì‹ íŒ¨í„´ (ìš°ì„ ìˆœìœ„ ìˆœ)
        patterns = [
            r'(\d+)\s*[-:]\s*(\d+)',  # "2-1" or "2:1"
            r'(\d+)\s+(\d+)',          # "2 1"
        ]

        for pattern in patterns:
            match = re.search(pattern, full_text)
            if match:
                try:
                    home = int(match.group(1))
                    away = int(match.group(2))

                    # ì ìˆ˜ ìœ íš¨ì„± ê²€ì‚¬ (0-20 ë²”ìœ„)
                    if 0 <= home <= 20 and 0 <= away <= 20:
                        return (home, away)
                except ValueError:
                    continue

        return None

    def _which_team_scored(
        self,
        old_score: Tuple[int, int],
        new_score: Tuple[int, int]
    ) -> str:
        """
        ì–´ëŠ íŒ€ì´ ë“ì í–ˆëŠ”ì§€ íŒë‹¨

        Args:
            old_score: ì´ì „ ì ìˆ˜
            new_score: ìƒˆ ì ìˆ˜

        Returns:
            'home', 'away', ë˜ëŠ” 'unknown'
        """
        if new_score[0] > old_score[0]:
            return 'home'
        elif new_score[1] > old_score[1]:
            return 'away'
        else:
            return 'unknown'

    def validate_final_score(
        self,
        expected_final_score: Tuple[int, int]
    ) -> List[str]:
        """
        ìµœì¢… ìŠ¤ì½”ì–´ ê²€ì¦ (ë†“ì¹œ ê³¨ í™•ì¸)

        Args:
            expected_final_score: ì˜ˆìƒ ìµœì¢… ì ìˆ˜ (ìˆ˜ë™ ì…ë ¥)

        Returns:
            ë†“ì¹œ ê³¨ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        if not self.goal_events:
            return [f"ê³¨ ì´ë²¤íŠ¸ê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì˜ˆìƒ: {expected_final_score[0]}-{expected_final_score[1]}"]

        final_detected = self.current_score
        missing_goals = []

        if final_detected != expected_final_score:
            self._log("\nâš ï¸  ì ìˆ˜ ë¶ˆì¼ì¹˜ ê°ì§€!")
            self._log(f"   ê°ì§€: {final_detected[0]}-{final_detected[1]}")
            self._log(f"   ì‹¤ì œ: {expected_final_score[0]}-{expected_final_score[1]}")

            # ë†“ì¹œ ê³¨ ê°œìˆ˜ ê³„ì‚°
            home_missing = expected_final_score[0] - final_detected[0]
            away_missing = expected_final_score[1] - final_detected[1]

            if home_missing > 0:
                missing_goals.append(f"Home team: {home_missing} goal(s) missed")
            if away_missing > 0:
                missing_goals.append(f"Away team: {away_missing} goal(s) missed")

            if home_missing < 0 or away_missing < 0:
                missing_goals.append("âš ï¸  ê°ì§€ëœ ì ìˆ˜ê°€ ì‹¤ì œë³´ë‹¤ ë§ìŠµë‹ˆë‹¤ (ì˜¤ê²€ì¶œ ê°€ëŠ¥ì„±)")
        else:
            self._log("\nâœ… ìµœì¢… ì ìˆ˜ ê²€ì¦ ì„±ê³µ!")
            self._log(f"   {final_detected[0]}-{final_detected[1]} (ëª¨ë“  ê³¨ ê°ì§€ ì™„ë£Œ)")

        return missing_goals


def detect_goals_from_scoreboard(
    video_path: str,
    baseline_interval_seconds: float = 2.0,
    enable_audio_boost: bool = False,
    audio_excitement_scores: Optional[Dict[float, float]] = None,
    use_gpu: bool = True,
    verbose: bool = True
) -> List[GoalEvent]:
    """
    í¸ì˜ í•¨ìˆ˜: ë¹„ë””ì˜¤ì—ì„œ ê³¨ ì´ë²¤íŠ¸ ì¶”ì¶œ

    Args:
        video_path: ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        baseline_interval_seconds: Baseline OCR ê°„ê²© (ì´ˆ) (default: 2.0)
        enable_audio_boost: ì˜¤ë””ì˜¤ í¥ë¶„ë„ ì—°ë™ í™œì„±í™” (default: False)
        audio_excitement_scores: ì˜¤ë””ì˜¤ í¥ë¶„ë„ ì ìˆ˜ ë”•ì…”ë„ˆë¦¬ {timestamp: excitement} (default: None)
        use_gpu: GPU ì‚¬ìš© ì—¬ë¶€ (default: True)
        verbose: ë¡œê·¸ ì¶œë ¥ ì—¬ë¶€ (default: True)

    Returns:
        ê³¨ ì´ë²¤íŠ¸ ë¦¬ìŠ¤íŠ¸

    Examples:
        # Phase 1: ê¸°ë³¸ ì‚¬ìš©
        >>> goals = detect_goals_from_scoreboard("match.mp4")

        # Phase 2: ì˜¤ë””ì˜¤ ì—°ë™
        >>> excitement_scores = {...}  # ì˜¤ë””ì˜¤ ë¶„ì„ ê²°ê³¼
        >>> goals = detect_goals_from_scoreboard(
        ...     "match.mp4",
        ...     enable_audio_boost=True,
        ...     audio_excitement_scores=excitement_scores
        ... )
    """
    detector = ScoreboardOCRDetector(
        video_path=video_path,
        baseline_interval_seconds=baseline_interval_seconds,
        enable_audio_boost=enable_audio_boost,
        use_gpu=use_gpu,
        verbose=verbose
    )

    if not detector.initialize():
        return []

    return detector.process_video(audio_excitement_scores=audio_excitement_scores)


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    import sys

    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•:")
        print("  Phase 1: python scoreboard_ocr_detector.py <video_file> [baseline_interval]")
        print("  Phase 2: python scoreboard_ocr_detector.py <video_file> [baseline_interval] --audio-boost")
        print("\nì˜ˆì‹œ:")
        print("  python scoreboard_ocr_detector.py match.mp4")
        print("  python scoreboard_ocr_detector.py match.mp4 2.0")
        print("  python scoreboard_ocr_detector.py match.mp4 2.0 --audio-boost")
        sys.exit(1)

    video_path = sys.argv[1]
    baseline_interval = 2.0
    enable_audio_boost = False

    # íŒŒë¼ë¯¸í„° íŒŒì‹±
    if len(sys.argv) > 2:
        try:
            baseline_interval = float(sys.argv[2])
        except ValueError:
            if sys.argv[2] == "--audio-boost":
                enable_audio_boost = True

    if len(sys.argv) > 3 and sys.argv[3] == "--audio-boost":
        enable_audio_boost = True

    # ê³¨ ê°ì§€
    print(f"ğŸ¬ ë¹„ë””ì˜¤: {video_path}")
    print(f"âš™ï¸  ëª¨ë“œ: {'Phase 2 (í•˜ì´ë¸Œë¦¬ë“œ)' if enable_audio_boost else 'Phase 1 (ê¸°ë³¸)'}")
    print(f"â±ï¸  Baseline ê°„ê²©: {baseline_interval}ì´ˆ\n")

    goal_events = detect_goals_from_scoreboard(
        video_path,
        baseline_interval_seconds=baseline_interval,
        enable_audio_boost=enable_audio_boost
    )

    if goal_events:
        print(f"\nâœ… ì´ {len(goal_events)}ê°œ ê³¨ ê°ì§€:")
        for i, event in enumerate(goal_events, 1):
            print(f"  {i}. {event}")
    else:
        print("\nâš ï¸  ê³¨ì„ ê°ì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    # JSON íŒŒì¼ë¡œ ì €ì¥
    output_dir = Path("ocr_output")
    output_dir.mkdir(exist_ok=True)

    # íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜ íŒŒì¼ëª…
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    video_name = Path(video_path).stem
    output_file = output_dir / f"{video_name}_{timestamp}.json"

    # JSON ë°ì´í„° ìƒì„±
    result_data = {
        "video_path": video_path,
        "processing_date": datetime.now().isoformat(),
        "baseline_interval_seconds": baseline_interval,
        "audio_boost_enabled": enable_audio_boost,
        "total_goals_detected": len(goal_events),
        "goals": [event.to_dict() for event in goal_events]
    }

    # JSON íŒŒì¼ ì €ì¥
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(result_data, f, indent=2, ensure_ascii=False)

    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_file}")
