"""
ê²½ê¸° ì¤‘ê³„ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ í•˜ì´ë¼ì´íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” ëª¨ë“ˆ
"""

import os
import json
import time
from pathlib import Path
from typing import List, Dict
from dotenv import load_dotenv
import google.generativeai as genai


class TranscriptAnalyzer:
    """ì¤‘ê³„ í…ìŠ¤íŠ¸ ë¶„ì„ê¸°"""

    def __init__(self, api_key: str = None, verbose: bool = True):
        """
        ì´ˆê¸°í™”

        Args:
            api_key: Google API í‚¤ (Noneì´ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ)
            verbose: ì§„í–‰ ìƒí™© ì¶œë ¥ ì—¬ë¶€
        """
        self.verbose = verbose

        # .env íŒŒì¼ ë¡œë“œ
        load_dotenv()

        # API í‚¤ ì„¤ì •
        self.api_key = api_key or os.getenv("GOOGLE_API_KEY")
        if not self.api_key:
            raise ValueError(
                "GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"
                ".env íŒŒì¼ì— GOOGLE_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.\n"
                "ë°œê¸‰: https://aistudio.google.com/apikey"
            )

        # Gemini ì„¤ì •
        genai.configure(api_key=self.api_key)
        self.model = genai.GenerativeModel('gemini-2.5-flash')

    def analyze_transcript(
        self, transcript_path: str, output_json_path: str = None
    ) -> List[Dict]:
        """
        ì¤‘ê³„ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ í•˜ì´ë¼ì´íŠ¸ ì¶”ì¶œ

        Args:
            transcript_path: ì¤‘ê³„ í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ
            output_json_path: ê²°ê³¼ JSON ì €ì¥ ê²½ë¡œ (Noneì´ë©´ ì €ì¥ ì•ˆí•¨)

        Returns:
            í•˜ì´ë¼ì´íŠ¸ ë¦¬ìŠ¤íŠ¸
        """
        total_start_time = time.time()

        # 1ë‹¨ê³„: ì¤‘ê³„ í…ìŠ¤íŠ¸ ì½ê¸°
        if self.verbose:
            print("\n" + "=" * 60)
            print("ğŸ“„ ì¤‘ê³„ í…ìŠ¤íŠ¸ ë¶„ì„ ì‹œì‘")
            print("=" * 60)
            print(f"ğŸ“‚ ì…ë ¥ íŒŒì¼: {transcript_path}")

        step_start = time.time()
        transcript_text = self._read_transcript(transcript_path)
        step_time = time.time() - step_start

        if self.verbose:
            text_length = len(transcript_text)
            lines = transcript_text.count('\n') + 1
            print(f"âœ… [1/3] íŒŒì¼ ì½ê¸° ì™„ë£Œ ({step_time:.2f}ì´ˆ)")
            print(f"   ğŸ“Š í…ìŠ¤íŠ¸ ê¸¸ì´: {text_length:,}ì ({lines}ì¤„)")

        # 2ë‹¨ê³„: Geminië¡œ ë¶„ì„
        if self.verbose:
            print(f"\nğŸ¤– [2/3] AI ë¶„ì„ ì¤‘...")
            print(f"   â³ Gemini API í˜¸ì¶œ ì¤‘ (ì•½ 10-30ì´ˆ ì†Œìš”)")

        step_start = time.time()
        highlights = self._extract_highlights(transcript_text)
        step_time = time.time() - step_start

        if self.verbose:
            print(f"âœ… [2/3] AI ë¶„ì„ ì™„ë£Œ ({step_time:.2f}ì´ˆ)")
            print(f"   ğŸ“Œ ì¶”ì¶œëœ í•˜ì´ë¼ì´íŠ¸: {len(highlights)}ê°œ")

        # 3ë‹¨ê³„: JSONìœ¼ë¡œ ì €ì¥
        if output_json_path:
            if self.verbose:
                print(f"\nğŸ’¾ [3/3] ê²°ê³¼ ì €ì¥ ì¤‘...")

            step_start = time.time()
            self._save_json(highlights, output_json_path)
            step_time = time.time() - step_start

            if self.verbose:
                print(f"âœ… [3/3] ì €ì¥ ì™„ë£Œ ({step_time:.2f}ì´ˆ)")
                print(f"   ğŸ“ ì¶œë ¥ íŒŒì¼: {output_json_path}")

        total_time = time.time() - total_start_time

        if self.verbose:
            print("\n" + "=" * 60)
            print(f"âœ¨ ì „ì²´ ì‘ì—… ì™„ë£Œ! (ì´ {total_time:.2f}ì´ˆ)")
            print("=" * 60)

        return highlights

    def _read_transcript(self, file_path: str) -> str:
        """ì¤‘ê³„ í…ìŠ¤íŠ¸ íŒŒì¼ ì½ê¸°"""
        path = Path(file_path)
        if not path.exists():
            raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")

        with open(path, 'r', encoding='utf-8') as f:
            return f.read()

    def _extract_highlights(self, transcript: str) -> List[Dict]:
        """Geminië¥¼ ì‚¬ìš©í•˜ì—¬ í•˜ì´ë¼ì´íŠ¸ ì¶”ì¶œ"""

        prompt = f"""
Analyze the following soccer match commentary and extract ONLY goals and key chances.

Commentary text:
```
{transcript}
```

Requirements:
1. Extract ONLY two types of highlights:
   - "goal": Actual goals scored
   - "chance": Clear goal-scoring opportunities (shots on target, near misses)

2. **Create SEPARATE highlights for EACH distinct event**:
   - Do NOT merge multiple events into one giant highlight
   - Each goal or chance should be its own highlight
   - Maximum duration per highlight: **40 seconds**
   - Minimum duration per highlight: 15 seconds
   - Recommended: 20-30 seconds per highlight

3. Timing is CRITICAL:
   - Include sufficient context BEFORE the moment (build-up play, 3-5 seconds)
   - Include sufficient context AFTER the moment (celebrations/replays, 3-5 seconds)
   - Analyze the commentary to determine appropriate padding
   - **Do NOT create highlights longer than 40 seconds**

4. **Sort highlights by TIME (chronological order)**:
   - ALWAYS return highlights in chronological order (earliest first)
   - Never put a later event before an earlier event

5. Merge adjacent highlights ONLY if necessary:
   - If two highlights are within 3 seconds of each other, merge them into ONE highlight
   - Example: If highlight A ends at 350s and highlight B starts at 352s â†’ merge into single highlight from A.start to B.end
   - **After merging, if duration exceeds 40s, split into separate highlights**

6. Time format:
   - Convert "[MM:SS.S]" or "MM:SS" format to seconds (e.g., "[1:24.5]" = 84.5 seconds)
   - start: beginning of context (including build-up)
   - end: end of context (including celebration/replay)

7. Output format must be a JSON array:
```json
[
  {{
    "start": 24.0,
    "end": 52.0,
    "type": "goal",
    "description": "ë§ˆíŠ¸íƒ€ í—¤ë”ê³¨ (1-0). ë¼ë§ˆìŠ¤ ê³¨í‚¤í¼ë¥¼ ìƒëŒ€ë¡œ ê°•ë ¥í•œ í—¤ë”ë¡œ ì„ ì œê³¨ ê¸°ë¡."
  }},
  {{
    "start": 112.0,
    "end": 126.0,
    "type": "goal",
    "description": "ì§€ê·¹í•´ì§€ í”„ë¦¬í‚¥ ì›ë”ê³¨ (2-0). í™˜ìƒì ì¸ ê°ë„ì—ì„œ ê³¨ë§ì„ í”ë“¤ë©° ì¶”ê°€ê³¨ ê¸°ë¡."
  }}
]
```

**Important**:
- Output ONLY the JSON array. No other text or explanations.
- Do NOT use code blocks (```).
- Output pure JSON only.
- Write descriptions in Korean.
- **CRITICAL**: Return highlights in CHRONOLOGICAL ORDER (sorted by start time)
- **CRITICAL**: Each highlight must be 15-40 seconds. Do NOT create highlights longer than 40 seconds.
- **CRITICAL**: Create SEPARATE highlights for each distinct event (goal/chance).
"""

        # Gemini API í˜¸ì¶œ
        response = self.model.generate_content(prompt)
        response_text = response.text.strip()

        # JSON íŒŒì‹±
        highlights = self._parse_response(response_text)

        # ì¸ì ‘ í•˜ì´ë¼ì´íŠ¸ ë³‘í•© (Geminiê°€ ëª»í•  ê²½ìš° ëŒ€ë¹„)
        highlights = self._merge_adjacent_highlights(highlights)

        return highlights

    def _parse_response(self, response_text: str) -> List[Dict]:
        """Gemini ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        try:
            # ì½”ë“œ ë¸”ë¡ ì œê±° (ìˆì„ ê²½ìš°)
            response_text = response_text.strip()
            if response_text.startswith('```'):
                # ```json ... ``` í˜•ì‹ ì²˜ë¦¬
                lines = response_text.split('\n')
                response_text = '\n'.join(lines[1:-1])

            # JSON íŒŒì‹±
            highlights = json.loads(response_text)

            # ê²€ì¦
            if not isinstance(highlights, list):
                raise ValueError("ì‘ë‹µì´ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤")

            # ê° í•­ëª© ê²€ì¦
            for i, highlight in enumerate(highlights):
                required_fields = ['start', 'end', 'type', 'description']
                for field in required_fields:
                    if field not in highlight:
                        raise ValueError(
                            f"í•˜ì´ë¼ì´íŠ¸ #{i+1}ì— '{field}' í•„ë“œê°€ ì—†ìŠµë‹ˆë‹¤"
                        )

            return highlights

        except json.JSONDecodeError as e:
            print(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            print(f"ì‘ë‹µ í…ìŠ¤íŠ¸:\n{response_text}")
            raise ValueError(f"Gemini ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")

    def _merge_adjacent_highlights(self, highlights: List[Dict], gap_threshold: float = 3.0) -> List[Dict]:
        """ì¸ì ‘í•œ í•˜ì´ë¼ì´íŠ¸ë¥¼ ë³‘í•©

        Args:
            highlights: í•˜ì´ë¼ì´íŠ¸ ë¦¬ìŠ¤íŠ¸
            gap_threshold: ë³‘í•© ê¸°ì¤€ ê°„ê²©(ì´ˆ) - 3ì´ˆ ì´í•˜ë©´ ë³‘í•©

        Returns:
            ë³‘í•©ëœ í•˜ì´ë¼ì´íŠ¸ ë¦¬ìŠ¤íŠ¸
        """
        if not highlights:
            return highlights

        # ì‹œì‘ ì‹œê°„ ê¸°ì¤€ ì •ë ¬
        sorted_highlights = sorted(highlights, key=lambda x: x['start'])

        merged = []
        current = sorted_highlights[0].copy()

        for next_h in sorted_highlights[1:]:
            gap = next_h['start'] - current['end']

            if gap <= gap_threshold:
                # ë³‘í•©: end ì‹œê°„ ì—°ì¥, description í•©ì¹¨
                current['end'] = next_h['end']
                # ê°™ì€ íƒ€ì…ì´ë©´ description í•©ì¹¨
                if current['type'] == next_h['type']:
                    current['description'] += f" / {next_h['description']}"
                else:
                    # ë‹¤ë¥¸ íƒ€ì…ì´ë©´ "goal + chance" í˜•ì‹ìœ¼ë¡œ
                    current['type'] = f"{current['type']}+{next_h['type']}"
                    current['description'] += f" / {next_h['description']}"
            else:
                # ê°„ê²©ì´ í¬ë©´ ë³„ë„ í•˜ì´ë¼ì´íŠ¸ë¡œ ìœ ì§€
                merged.append(current)
                current = next_h.copy()

        # ë§ˆì§€ë§‰ í•˜ì´ë¼ì´íŠ¸ ì¶”ê°€
        merged.append(current)

        return merged

    def _save_json(self, highlights: List[Dict], output_path: str) -> None:
        """í•˜ì´ë¼ì´íŠ¸ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        path = Path(output_path)
        path.parent.mkdir(parents=True, exist_ok=True)

        with open(path, 'w', encoding='utf-8') as f:
            json.dump(highlights, f, ensure_ascii=False, indent=2)

        print(f"âœ… í•˜ì´ë¼ì´íŠ¸ ì €ì¥ ì™„ë£Œ: {output_path}")


def analyze_transcript_file(
    transcript_path: str,
    output_json_path: str = None,
    api_key: str = None
) -> List[Dict]:
    """
    í¸ì˜ í•¨ìˆ˜: ì¤‘ê³„ í…ìŠ¤íŠ¸ íŒŒì¼ ë¶„ì„

    Args:
        transcript_path: ì¤‘ê³„ í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ
        output_json_path: ê²°ê³¼ JSON ì €ì¥ ê²½ë¡œ
        api_key: Google API í‚¤

    Returns:
        í•˜ì´ë¼ì´íŠ¸ ë¦¬ìŠ¤íŠ¸
    """
    analyzer = TranscriptAnalyzer(api_key=api_key)
    return analyzer.analyze_transcript(transcript_path, output_json_path)


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    import sys

    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python transcript_analyzer.py <transcript_file> [output_json]")
        print("\nì˜ˆì‹œ:")
        print("  python transcript_analyzer.py input/match_transcript.txt")
        print("  python transcript_analyzer.py input/match_transcript.txt output/highlights.json")
        sys.exit(1)

    transcript_file = sys.argv[1]
    output_file = sys.argv[2] if len(sys.argv) > 2 else None

    try:
        highlights = analyze_transcript_file(transcript_file, output_file)

        print(f"\nâœ… ì´ {len(highlights)}ê°œì˜ í•˜ì´ë¼ì´íŠ¸ë¥¼ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤:\n")
        for i, h in enumerate(highlights, 1):
            print(f"{i}. [{h['type'].upper()}] {h['start']:.1f}s - {h['end']:.1f}s")
            print(f"   {h['description']}\n")

    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
