"""
ë¹„ë””ì˜¤ íŒŒì¼ë¡œ ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸

ë¹„ë””ì˜¤ì—ì„œ ì˜¤ë””ì˜¤ ì¶”ì¶œ â†’ í•˜ì´ë¼ì´íŠ¸ í•„í„°ë§ â†’ STT â†’ Gemini ë¶„ì„
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

import subprocess
import time
from src.audio import AudioHighlightFilter, WhisperTranscriber
from src.ai.transcript_analyzer import TranscriptAnalyzer
import json


def extract_audio_from_video(video_path: str, audio_path: str) -> bool:
    """
    ë¹„ë””ì˜¤ íŒŒì¼ì—ì„œ ì˜¤ë””ì˜¤ ì¶”ì¶œ (FFmpeg ì‚¬ìš©)

    Args:
        video_path: ì…ë ¥ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        audio_path: ì¶œë ¥ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ

    Returns:
        bool: ì„±ê³µ ì—¬ë¶€
    """
    print("ğŸ¬ ë¹„ë””ì˜¤ì—ì„œ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì¤‘...")
    print(f"   ì…ë ¥: {video_path}")
    print(f"   ì¶œë ¥: {audio_path}")

    # FFmpeg ëª…ë ¹ì–´
    # -vn: ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì œê±°
    # -acodec libmp3lame: MP3 ì¸ì½”ë”
    # -q:a 2: ê³ í’ˆì§ˆ (0-9, ë‚®ì„ìˆ˜ë¡ ê³ í’ˆì§ˆ)
    cmd = [
        "ffmpeg",
        "-i", video_path,
        "-vn",  # ë¹„ë””ì˜¤ ì—†ìŒ
        "-acodec", "libmp3lame",  # MP3 ì¸ì½”ë”
        "-q:a", "2",  # ê³ í’ˆì§ˆ
        "-y",  # ë®ì–´ì“°ê¸°
        audio_path
    ]

    try:
        result = subprocess.run(
            cmd,
            check=True,
            capture_output=True,
            text=True
        )
        print(f"âœ… ì˜¤ë””ì˜¤ ì¶”ì¶œ ì™„ë£Œ: {audio_path}")
        return True

    except subprocess.CalledProcessError as e:
        print(f"âŒ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì‹¤íŒ¨:")
        print(f"   {e.stderr}")
        return False


def get_video_info(video_path: str) -> dict:
    """
    ë¹„ë””ì˜¤ ì •ë³´ í™•ì¸ (ffprobe ì‚¬ìš©)

    Args:
        video_path: ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ

    Returns:
        dict: ë¹„ë””ì˜¤ ì •ë³´
    """
    cmd = [
        "ffprobe",
        "-v", "quiet",
        "-print_format", "json",
        "-show_format",
        "-show_streams",
        video_path
    ]

    try:
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        info = json.loads(result.stdout)

        # ë¹„ë””ì˜¤ ì •ë³´ ì¶”ì¶œ
        video_stream = None
        audio_stream = None

        for stream in info.get('streams', []):
            if stream['codec_type'] == 'video' and not video_stream:
                video_stream = stream
            elif stream['codec_type'] == 'audio' and not audio_stream:
                audio_stream = stream

        duration = float(info.get('format', {}).get('duration', 0))

        return {
            'duration': duration,
            'video_codec': video_stream.get('codec_name') if video_stream else None,
            'video_resolution': f"{video_stream.get('width')}x{video_stream.get('height')}" if video_stream else None,
            'audio_codec': audio_stream.get('codec_name') if audio_stream else None,
            'audio_sample_rate': audio_stream.get('sample_rate') if audio_stream else None,
        }

    except Exception as e:
        print(f"âš ï¸  ë¹„ë””ì˜¤ ì •ë³´ í™•ì¸ ì‹¤íŒ¨: {e}")
        return {}


def test_video_pipeline(video_path: str, output_dir: str = "output"):
    """
    ë¹„ë””ì˜¤ íŒŒì¼ë¡œ ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸

    Args:
        video_path: ì…ë ¥ ë¹„ë””ì˜¤ íŒŒì¼
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬

    Returns:
        Dict: ì „ì²´ ê²°ê³¼
    """
    print("=" * 70)
    print("ğŸ¬ ë¹„ë””ì˜¤ íŒŒì¼ ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸")
    print("=" * 70)
    print(f"ğŸ“‚ ì…ë ¥ ë¹„ë””ì˜¤: {video_path}\n")

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    Path(output_dir).mkdir(parents=True, exist_ok=True)

    # ë¹„ë””ì˜¤ íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not Path(video_path).exists():
        print(f"âŒ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
        return None

    # ë¹„ë””ì˜¤ ì •ë³´ í™•ì¸
    print("ğŸ“Š ë¹„ë””ì˜¤ ì •ë³´ í™•ì¸ ì¤‘...")
    video_info = get_video_info(video_path)

    if video_info:
        duration_minutes = int(video_info['duration'] // 60)
        duration_seconds = int(video_info['duration'] % 60)

        print(f"   â±ï¸  ê¸¸ì´: {duration_minutes}ë¶„ {duration_seconds}ì´ˆ")
        print(f"   ğŸ¥ ë¹„ë””ì˜¤: {video_info.get('video_codec')} - {video_info.get('video_resolution')}")
        print(f"   ğŸ”Š ì˜¤ë””ì˜¤: {video_info.get('audio_codec')} - {video_info.get('audio_sample_rate')} Hz")
    print()

    total_start = time.time()

    # ========================================
    # Step 0: ì˜¤ë””ì˜¤ ì¶”ì¶œ
    # ========================================
    print("[Step 0] ë¹„ë””ì˜¤ì—ì„œ ì˜¤ë””ì˜¤ ì¶”ì¶œ")
    print("-" * 70)

    step0_start = time.time()

    video_name = Path(video_path).stem
    audio_path = f"{output_dir}/{video_name}_audio.mp3"

    if not extract_audio_from_video(video_path, audio_path):
        print("âŒ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì‹¤íŒ¨. ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return None

    step0_time = time.time() - step0_start
    print(f"âœ… Step 0 ì™„ë£Œ ({step0_time:.1f}ì´ˆ)\n")

    # ========================================
    # Step 1: ì˜¤ë””ì˜¤ í•˜ì´ë¼ì´íŠ¸ í•„í„°ë§
    # ========================================
    print("[Step 1] ì˜¤ë””ì˜¤ í•˜ì´ë¼ì´íŠ¸ í•„í„°ë§")
    print("-" * 70)

    step1_start = time.time()

    audio_filter = AudioHighlightFilter(
        threshold_percentile=60,
        merge_gap=2.0,
        segment_duration=5.0,
        verbose=True
    )

    segments = audio_filter.filter_audio(audio_path)
    step1_time = time.time() - step1_start

    print(f"\nâœ… Step 1 ì™„ë£Œ ({step1_time:.1f}ì´ˆ)")
    print(f"   ì¶”ì¶œëœ êµ¬ê°„: {len(segments)}ê°œ")

    if segments:
        print(f"   êµ¬ê°„ ë¦¬ìŠ¤íŠ¸ (ì²˜ìŒ 5ê°œ):")
        for i, (start, end) in enumerate(segments[:5], 1):
            minutes = int(start // 60)
            seconds = int(start % 60)
            print(f"      {i}. {minutes:02d}:{seconds:02d} ~ {int(end//60):02d}:{int(end%60):02d} (ê¸¸ì´: {end-start:.1f}ì´ˆ)")
        if len(segments) > 5:
            print(f"      ... ì™¸ {len(segments)-5}ê°œ")

        # Step 1 ê²°ê³¼ ì €ì¥
        segments_data = [
            {
                'start': s,
                'end': e,
                'duration': e-s,
                'timestamp': f"{int(s//60):02d}:{int(s%60):02d}"
            }
            for s, e in segments
        ]
        with open(f"{output_dir}/step1_segments.json", 'w', encoding='utf-8') as f:
            json.dump(segments_data, f, indent=2, ensure_ascii=False)
        print(f"   ğŸ’¾ ì €ì¥: {output_dir}/step1_segments.json")

        # ì´ í•˜ì´ë¼ì´íŠ¸ ì‹œê°„
        total_highlight_time = sum(e - s for s, e in segments)
        print(f"   ğŸ“Š ì´ í•˜ì´ë¼ì´íŠ¸ ì‹œê°„: {total_highlight_time:.1f}ì´ˆ ({total_highlight_time/60:.1f}ë¶„)")

        if video_info.get('duration'):
            reduction = (1 - total_highlight_time / video_info['duration']) * 100
            print(f"   ğŸ“‰ ê°ì†Œìœ¨: {reduction:.1f}%")
    else:
        print("âŒ í•˜ì´ë¼ì´íŠ¸ êµ¬ê°„ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ í•´ê²°ì±…:")
        print("   1. threshold_percentile ê°’ì„ ë‚®ì¶°ë³´ì„¸ìš” (ì˜ˆ: 40)")
        print("   2. ì˜¤ë””ì˜¤ì— ì†Œë¦¬ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”")
        return None

    # ========================================
    # Step 2: Whisper STT
    # ========================================
    print("\n[Step 2] Whisper ìŒì„±-í…ìŠ¤íŠ¸ ë³€í™˜")
    print("-" * 70)

    step2_start = time.time()

    transcriber = WhisperTranscriber(
        model_size="base",
        device="auto",
        language="ko",
        verbose=True
    )

    result = transcriber.transcribe(audio_path, segments=segments)
    step2_time = time.time() - step2_start

    print(f"\nâœ… Step 2 ì™„ë£Œ ({step2_time:.1f}ì´ˆ)")
    print(f"   ì „ì²´ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(result['text'])}ì")
    print(f"   ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜: {len(result['segments'])}ê°œ")
    print(f"   ê°ì§€ëœ ì–¸ì–´: {result['language']}")

    if 'original_segments_count' in result:
        reduction = (1 - result['filtered_segments_count'] / result['original_segments_count']) * 100
        print(f"   ì„¸ê·¸ë¨¼íŠ¸ ê°ì†Œìœ¨: {reduction:.1f}%")

    # Step 2 ê²°ê³¼ ì €ì¥
    transcriber.save_transcript(result, f"{output_dir}/step2_transcript.txt", format="txt")
    transcriber.save_transcript(result, f"{output_dir}/step2_transcript.json", format="json")
    print(f"   ğŸ’¾ ì €ì¥: {output_dir}/step2_transcript.txt")
    print(f"   ğŸ’¾ ì €ì¥: {output_dir}/step2_transcript.json")

    # í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°
    if result['text']:
        print(f"\n   ğŸ“„ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 300ì):")
        preview = result['text'][:300]
        print(f"   {preview}{'...' if len(result['text']) > 300 else ''}")
    else:
        print(f"\n   âš ï¸  í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì˜¤ë””ì˜¤ì— ìŒì„±ì´ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    # íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨ í…ìŠ¤íŠ¸ ìƒì„± (Geminiìš©)
    timestamp_text = ""
    for seg in result['segments']:
        timestamp_text += f"[{seg['start']:.1f}s - {seg['end']:.1f}s] {seg['text']}\n"

    timestamp_path = f"{output_dir}/step2_transcript_with_timestamps.txt"
    with open(timestamp_path, 'w', encoding='utf-8') as f:
        f.write(timestamp_text)
    print(f"   ğŸ’¾ ì €ì¥: {timestamp_path}")

    # ========================================
    # Step 3: Gemini LLM ë¶„ì„
    # ========================================
    print("\n[Step 3] Gemini LLM í•˜ì´ë¼ì´íŠ¸ ë¶„ì„")
    print("-" * 70)

    step3_start = time.time()

    analyzer = TranscriptAnalyzer(verbose=True)

    highlights_path = f"{output_dir}/step3_highlights.json"
    highlights = analyzer.analyze_transcript(timestamp_path, highlights_path)
    step3_time = time.time() - step3_start

    print(f"\nâœ… Step 3 ì™„ë£Œ ({step3_time:.1f}ì´ˆ)")
    print(f"   ì¶”ì¶œëœ í•˜ì´ë¼ì´íŠ¸: {len(highlights)}ê°œ")
    print(f"   ğŸ’¾ ì €ì¥: {highlights_path}")

    # í•˜ì´ë¼ì´íŠ¸ ì¶œë ¥
    if highlights:
        print(f"\n   ğŸ¯ ì¶”ì¶œëœ í•˜ì´ë¼ì´íŠ¸:")
        for i, h in enumerate(highlights, 1):
            minutes = int(h['start'] // 60)
            seconds = int(h['start'] % 60)
            print(f"      {i}. [{minutes:02d}:{seconds:02d}] {h['type']}")
            print(f"         {h['description']}")

        # íƒ€ì…ë³„ í†µê³„
        type_counts = {}
        for h in highlights:
            type_counts[h['type']] = type_counts.get(h['type'], 0) + 1

        print(f"\n   ğŸ“Š íƒ€ì…ë³„ í†µê³„:")
        for htype, count in type_counts.items():
            print(f"      {htype}: {count}ê°œ")
    else:
        print("   âš ï¸  í•˜ì´ë¼ì´íŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    # ========================================
    # ìµœì¢… ìš”ì•½
    # ========================================
    total_time = time.time() - total_start

    print("\n" + "=" * 70)
    print("âœ¨ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
    print("=" * 70)

    print(f"\nâ±ï¸  ì†Œìš” ì‹œê°„:")
    print(f"   Step 0 (ì˜¤ë””ì˜¤ ì¶”ì¶œ): {step0_time:.1f}ì´ˆ")
    print(f"   Step 1 (ì˜¤ë””ì˜¤ í•„í„°ë§): {step1_time:.1f}ì´ˆ")
    print(f"   Step 2 (Whisper STT): {step2_time:.1f}ì´ˆ")
    print(f"   Step 3 (Gemini ë¶„ì„): {step3_time:.1f}ì´ˆ")
    print(f"   ì´ ì†Œìš” ì‹œê°„: {total_time:.1f}ì´ˆ ({total_time/60:.1f}ë¶„)")

    print(f"\nğŸ“Š ìµœì¢… í†µê³„:")
    if video_info.get('duration'):
        print(f"   ì›ë³¸ ë¹„ë””ì˜¤: {video_info['duration']:.0f}ì´ˆ ({video_info['duration']/60:.1f}ë¶„)")
    print(f"   ì¶”ì¶œëœ ì˜¤ë””ì˜¤ êµ¬ê°„: {len(segments)}ê°œ")
    print(f"   í…ìŠ¤íŠ¸ ì„¸ê·¸ë¨¼íŠ¸: {len(result['segments'])}ê°œ")
    print(f"   ìµœì¢… í•˜ì´ë¼ì´íŠ¸: {len(highlights)}ê°œ")

    print(f"\nğŸ“ ìƒì„±ëœ íŒŒì¼:")
    print(f"   âœ“ {audio_path}")
    print(f"   âœ“ {output_dir}/step1_segments.json")
    print(f"   âœ“ {output_dir}/step2_transcript.txt")
    print(f"   âœ“ {output_dir}/step2_transcript.json")
    print(f"   âœ“ {output_dir}/step2_transcript_with_timestamps.txt")
    print(f"   âœ“ {output_dir}/step3_highlights.json")

    return {
        'video_info': video_info,
        'audio_path': audio_path,
        'segments': segments,
        'transcript': result,
        'highlights': highlights,
        'timing': {
            'step0': step0_time,
            'step1': step1_time,
            'step2': step2_time,
            'step3': step3_time,
            'total': total_time
        }
    }


if __name__ == "__main__":
    import sys

    print("ğŸ¬ ë¹„ë””ì˜¤ íŒŒì¼ ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸")
    print("=" * 70)
    print()

    # ì…ë ¥ íŒŒì¼ í™•ì¸
    if len(sys.argv) > 1:
        video_path = sys.argv[1]
    else:
        # ê¸°ë³¸ê°’: korea_vs_brazil.mp4
        video_path = "input/korea_vs_brazil.mp4"
        print(f"ğŸ’¡ ì‚¬ìš©ë²•: python {Path(__file__).name} <video_file>")
        print(f"   ê¸°ë³¸ íŒŒì¼ ì‚¬ìš©: {video_path}\n")

    if not Path(video_path).exists():
        print(f"âŒ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
        print(f"\nğŸ’¡ í•´ê²° ë°©ë²•:")
        print(f"   1. 'input/' ë””ë ‰í† ë¦¬ì— ë¹„ë””ì˜¤ íŒŒì¼ ë„£ê¸°")
        print(f"   2. íŒŒì¼ ê²½ë¡œë¥¼ ì¸ìë¡œ ì „ë‹¬: python {Path(__file__).name} path/to/video.mp4")
        sys.exit(1)

    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    result = test_video_pipeline(video_path)

    if result and result['highlights']:
        print("\n" + "=" * 70)
        print("ğŸ“‹ ìµœì¢… í•˜ì´ë¼ì´íŠ¸ ìš”ì•½")
        print("=" * 70)

        for i, h in enumerate(result['highlights'], 1):
            minutes = int(h['start'] // 60)
            seconds = int(h['start'] % 60)
            print(f"{i}. [{minutes:02d}:{seconds:02d}] {h['type'].upper()}")
            print(f"   {h['description']}")

    print("\n" + "=" * 70)
    print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("=" * 70)
