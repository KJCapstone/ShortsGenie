import cv2
import json
import os
import numpy as np
from scenedetect import VideoManager, SceneManager
from scenedetect.detectors import ContentDetector

# ================= [ì„¤ì •ê°’] =================
VIDEO_PATH = "test2.mp4"                 # ì˜ìƒ íŒŒì¼ëª…
TEMPLATE_PATH = "scoreboard_template.png" # ì ìˆ˜íŒ ìº¡ì²˜ íŒŒì¼ëª…
OUT_JSON = "shots2.json"

# 1. ì¥ë©´ ê°ì§€ ë¯¼ê°ë„ (ë‚®ì„ìˆ˜ë¡ ì˜ˆë¯¼í•˜ê²Œ ìë¦„)
SCENE_THRESHOLD = 15.0 

# 2. ì ìˆ˜íŒ ë§¤ì¹­ ê¸°ì¤€ (0.6 ì´ìƒì´ë©´ ì ìˆ˜íŒ ìˆë‹¤ê³  íŒë‹¨)
MATCH_THRESHOLD = 0.6
# ===========================================

def calculate_green_ratio(frame):
    """ í™”ë©´ì— ì´ˆë¡ìƒ‰(ì”ë””)ì´ ì–¼ë§ˆë‚˜ ìˆëŠ”ì§€ %ë¡œ ê³„ì‚° """
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
    # ì´ˆë¡ìƒ‰ ë²”ìœ„ (ì¶•êµ¬ì¥ ì”ë””ìƒ‰)
    lower_green = np.array([35, 40, 40])
    upper_green = np.array([85, 255, 255])
    mask = cv2.inRange(hsv, lower_green, upper_green)
    return cv2.countNonZero(mask) / (frame.shape[0] * frame.shape[1])

def step1_analyze():
    if not os.path.exists(VIDEO_PATH):
        print("âŒ ì˜ìƒ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    print("ğŸš€ [1ë‹¨ê³„] ì§€ëŠ¥í˜• ë¶„ì„ ì‹œì‘ (Brain Mode)...")

    # 1. ì ìˆ˜íŒ í…œí”Œë¦¿ ë¡œë“œ
    template = None
    if os.path.exists(TEMPLATE_PATH):
        template = cv2.imread(TEMPLATE_PATH, cv2.IMREAD_GRAYSCALE)
        print("   âœ… ì ìˆ˜íŒ í…œí”Œë¦¿ ë¡œë“œë¨ (ë¦¬í”Œë ˆì´ ìë™ ê°ì§€ ON)")
    else:
        print("   âš ï¸ í…œí”Œë¦¿ ì—†ìŒ (ë¦¬í”Œë ˆì´ ê°ì§€ ë¶ˆê°€)")

    # 2. ì»· ê°ì§€ (PySceneDetect)
    print("   ğŸ” ì¥ë©´ ì „í™˜ ì§€ì  ì°¾ëŠ” ì¤‘...")
    video_manager = VideoManager([VIDEO_PATH])
    scene_manager = SceneManager()
    # min_scene_len=15: ìµœì†Œ 0.5ì´ˆ ì´ìƒ ë˜ì–´ì•¼ ì»·ìœ¼ë¡œ ì¸ì • (ë„ˆë¬´ ì˜ê²Œ ìª¼ê°œì§ ë°©ì§€)
    scene_manager.add_detector(ContentDetector(threshold=SCENE_THRESHOLD, min_scene_len=15))
    
    video_manager.start()
    scene_manager.detect_scenes(frame_source=video_manager)
    scene_list = scene_manager.get_scene_list(video_manager.get_base_timecode())
    video_manager.release()
    
    print(f"   âœ… ì´ {len(scene_list)}ê°œì˜ ì»· ë°œê²¬.")

    # 3. ê° ì¥ë©´ ìƒì„¸ ë¶„ì„ (CV2 í™œìš©)
    cap = cv2.VideoCapture(VIDEO_PATH)
    final_shots = []

    print("   ğŸ§  ê° ì¥ë©´ ë‚´ìš© ë¶„ì„ ì¤‘ (Replay & Shot Type)...")

    for i, scene in enumerate(scene_list):
        start = scene[0].get_seconds()
        end = scene[1].get_seconds()
        duration = end - start

        if duration < 0.5: continue # ë„ˆë¬´ ì§§ì€ ê±´ íŒ¨ìŠ¤

        # ì¤‘ê°„ í”„ë ˆì„ ì¶”ì¶œ
        mid_pos = start + (duration / 2)
        cap.set(cv2.CAP_PROP_POS_MSEC, mid_pos * 1000)
        ret, frame = cap.read()
        if not ret: continue

        label = "unknown"
        is_replay = False

        # [A] ë¦¬í”Œë ˆì´ ê²€ì‚¬ (ì ìˆ˜íŒ ì°¾ê¸°)
        if template is not None:
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            # ì†ë„ë¥¼ ìœ„í•´ ì¢Œì¸¡ ìƒë‹¨(300x600)ë§Œ ê²€ì‚¬
            roi_h, roi_w = 300, 600
            if gray.shape[0] > roi_h and gray.shape[1] > roi_w:
                roi = gray[0:roi_h, 0:roi_w]
            else:
                roi = gray
            
            res = cv2.matchTemplate(roi, template, cv2.TM_CCOEFF_NORMED)
            _, max_val, _, _ = cv2.minMaxLoc(res)
            
            if max_val < MATCH_THRESHOLD: # ì ìˆ˜íŒì´ ì—†ìœ¼ë©´?
                label = "replay"
                is_replay = True
        
        # [B] ìƒ· ì¢…ë¥˜ ê²€ì‚¬ (ì”ë”” ë¹„ìœ¨) - ë¦¬í”Œë ˆì´ê°€ ì•„ë‹ ë•Œë§Œ
        if not is_replay:
            green_ratio = calculate_green_ratio(frame)
            if green_ratio > 0.60:     # 60% ì´ìƒ ì”ë”” -> Wide
                label = "wide"
            elif green_ratio > 0.20:   # 20~60% ì”ë”” -> Close
                label = "close"
            else:                      # ì”ë”” ê±°ì˜ ì—†ìŒ -> Audience
                label = "audience"

        final_shots.append({
            "label": label,
            "start": start,
            "end": end
        })

    cap.release()

    with open(OUT_JSON, "w", encoding="utf-8") as f:
        json.dump(final_shots, f, indent=2, ensure_ascii=False)

    print(f"\nâœ¨ ë¶„ì„ ì™„ë£Œ! '{OUT_JSON}' ìƒì„±ë¨.")
    print("ğŸ‘‰ ì´ì œ step2_cut.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")

if __name__ == "__main__":
    step1_analyze()