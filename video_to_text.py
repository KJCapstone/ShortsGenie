import ffmpeg
from faster_whisper import WhisperModel
import torch

# ğŸ¬ 1ï¸âƒ£ ë³€í™˜í•  ì¶•êµ¬ ì˜ìƒ ê²½ë¡œ
video_path = "match.mp4"
audio_path = "match_audio.wav"

# ğŸ§ 2ï¸âƒ£ ì˜ìƒ â†’ ì˜¤ë””ì˜¤ ì¶”ì¶œ (16kHz, ëª¨ë…¸)
print("ğŸ§ ì˜ìƒì—ì„œ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì¤‘...")
ffmpeg.input(video_path).output(
    audio_path, ac=1, ar=16000, format="wav"
).run(overwrite_output=True)

# âš™ï¸ 3ï¸âƒ£ Whisper ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"âš™ï¸ Whisper ëª¨ë¸ ë¡œë“œ ì¤‘... (device={device})")

model = WhisperModel("small", device=device)  # tiny/base/small/medium/large ì„ íƒ ê°€ëŠ¥

# ğŸ—£ï¸ 4ï¸âƒ£ ìŒì„± â†’ í…ìŠ¤íŠ¸ ë³€í™˜
print("ğŸ—£ï¸ ìŒì„± ì¸ì‹ ì‹œì‘...")
segments, info = model.transcribe(audio_path, beam_size=5, language="ko")

# ğŸ“ 5ï¸âƒ£ ê²°ê³¼ ì €ì¥
output_txt = "match_transcript.txt"
with open(output_txt, "w", encoding="utf-8") as f:
    for seg in segments:
        line = f"[{seg.start:.1f}~{seg.end:.1f}] {seg.text.strip()}\n"
        print(line, end="")
        f.write(line)

print(f"\nâœ… ë³€í™˜ ì™„ë£Œ! ê²°ê³¼ ì €ì¥: {output_txt}")
