"""
ì „ì²´ íŒŒì´í”„ë¼ì¸ í†µí•© í…ŒìŠ¤íŠ¸

ì˜¤ë””ì˜¤ í•„í„°ë§ â†’ Whisper STT â†’ Gemini ë¶„ì„ â†’ JSON ì¶œë ¥
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.audio import AudioHighlightFilter, WhisperTranscriber
from src.ai.transcript_analyzer import TranscriptAnalyzer
import json
import time


def test_pipeline_step_by_step(audio_path: str):
    """
    ë‹¨ê³„ë³„ ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸

    Args:
        audio_path: ì…ë ¥ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ

    Returns:
        Dict: ì „ì²´ ê²°ê³¼
    """

    print("=" * 70)
    print("ğŸ¬ ì „ì²´ íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ë³„ í…ŒìŠ¤íŠ¸")
    print("=" * 70)
    print(f"ğŸ“‚ ì…ë ¥ íŒŒì¼: {audio_path}\n")

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    Path("output").mkdir(exist_ok=True)

    # ========================================
    # Step 1: ì˜¤ë””ì˜¤ í•˜ì´ë¼ì´íŠ¸ í•„í„°ë§
    # ========================================
    print("[Step 1] ì˜¤ë””ì˜¤ í•˜ì´ë¼ì´íŠ¸ í•„í„°ë§")
    print("-" * 70)

    step1_start = time.time()

    audio_filter = AudioHighlightFilter(
        threshold_percentile=60,
        merge_gap=2.0,
        segment_duration=5.0,
        verbose=True
    )

    segments = audio_filter.filter_audio(audio_path)
    step1_time = time.time() - step1_start

    print(f"\nâœ… Step 1 ì™„ë£Œ ({step1_time:.1f}ì´ˆ)")
    print(f"   ì¶”ì¶œëœ êµ¬ê°„: {len(segments)}ê°œ")

    if segments:
        print(f"   êµ¬ê°„ ë¦¬ìŠ¤íŠ¸:")
        for i, (start, end) in enumerate(segments[:5], 1):  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
            print(f"      {i}. {start:.1f}ì´ˆ ~ {end:.1f}ì´ˆ (ê¸¸ì´: {end-start:.1f}ì´ˆ)")
        if len(segments) > 5:
            print(f"      ... ì™¸ {len(segments)-5}ê°œ")

        # Step 1 ê²°ê³¼ ì €ì¥
        segments_data = [{'start': s, 'end': e, 'duration': e-s} for s, e in segments]
        with open("output/step1_segments.json", 'w', encoding='utf-8') as f:
            json.dump(segments_data, f, indent=2, ensure_ascii=False)
        print(f"   ğŸ’¾ ì €ì¥: output/step1_segments.json")
    else:
        print("âŒ í•˜ì´ë¼ì´íŠ¸ êµ¬ê°„ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ í•´ê²°ì±…: threshold_percentile ê°’ì„ ë‚®ì¶°ë³´ì„¸ìš” (ì˜ˆ: 40)")
        return None

    # ========================================
    # Step 2: Whisper STT
    # ========================================
    print("\n[Step 2] Whisper ìŒì„±-í…ìŠ¤íŠ¸ ë³€í™˜")
    print("-" * 70)

    step2_start = time.time()

    transcriber = WhisperTranscriber(
        model_size="base",
        device="auto",
        language="ko",
        verbose=True
    )

    result = transcriber.transcribe(audio_path, segments=segments)
    step2_time = time.time() - step2_start

    print(f"\nâœ… Step 2 ì™„ë£Œ ({step2_time:.1f}ì´ˆ)")
    print(f"   ì „ì²´ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(result['text'])}ì")
    print(f"   ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜: {len(result['segments'])}ê°œ")
    print(f"   ê°ì§€ëœ ì–¸ì–´: {result['language']}")

    if 'original_segments_count' in result:
        reduction = (1 - result['filtered_segments_count'] / result['original_segments_count']) * 100
        print(f"   ì„¸ê·¸ë¨¼íŠ¸ ê°ì†Œìœ¨: {reduction:.1f}%")

    # Step 2 ê²°ê³¼ ì €ì¥
    transcriber.save_transcript(result, "output/step2_transcript.txt", format="txt")
    transcriber.save_transcript(result, "output/step2_transcript.json", format="json")
    print(f"   ğŸ’¾ ì €ì¥: output/step2_transcript.txt")
    print(f"   ğŸ’¾ ì €ì¥: output/step2_transcript.json")

    # í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°
    print(f"\n   ğŸ“„ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 200ì):")
    preview = result['text'][:200]
    print(f"   {preview}{'...' if len(result['text']) > 200 else ''}")

    # íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨ í…ìŠ¤íŠ¸ ìƒì„± (Geminiìš©)
    timestamp_text = ""
    for seg in result['segments']:
        timestamp_text += f"[{seg['start']:.1f}s - {seg['end']:.1f}s] {seg['text']}\n"

    timestamp_path = "output/step2_transcript_with_timestamps.txt"
    with open(timestamp_path, 'w', encoding='utf-8') as f:
        f.write(timestamp_text)
    print(f"   ğŸ’¾ ì €ì¥: {timestamp_path}")

    # ========================================
    # Step 3: Gemini LLM ë¶„ì„
    # ========================================
    print("\n[Step 3] Gemini LLM í•˜ì´ë¼ì´íŠ¸ ë¶„ì„")
    print("-" * 70)

    step3_start = time.time()

    analyzer = TranscriptAnalyzer(verbose=True)

    highlights_path = "output/step3_highlights.json"
    highlights = analyzer.analyze_transcript(timestamp_path, highlights_path)
    step3_time = time.time() - step3_start

    print(f"\nâœ… Step 3 ì™„ë£Œ ({step3_time:.1f}ì´ˆ)")
    print(f"   ì¶”ì¶œëœ í•˜ì´ë¼ì´íŠ¸: {len(highlights)}ê°œ")
    print(f"   ğŸ’¾ ì €ì¥: {highlights_path}")

    # í•˜ì´ë¼ì´íŠ¸ ì¶œë ¥
    if highlights:
        print(f"\n   ğŸ¯ ì¶”ì¶œëœ í•˜ì´ë¼ì´íŠ¸:")
        for i, h in enumerate(highlights, 1):
            print(f"      {i}. [{h['start']:.1f}s - {h['end']:.1f}s] {h['type']}")
            print(f"         {h['description']}")
    else:
        print("   âš ï¸  í•˜ì´ë¼ì´íŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    # ========================================
    # ìµœì¢… ìš”ì•½
    # ========================================
    total_time = step1_time + step2_time + step3_time

    print("\n" + "=" * 70)
    print("âœ¨ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
    print("=" * 70)

    print(f"\nğŸ“Š ìµœì¢… í†µê³„:")
    print(f"   Step 1: {len(segments)}ê°œ ì˜¤ë””ì˜¤ êµ¬ê°„ ì¶”ì¶œ ({step1_time:.1f}ì´ˆ)")
    print(f"   Step 2: {len(result['segments'])}ê°œ í…ìŠ¤íŠ¸ ì„¸ê·¸ë¨¼íŠ¸ ë³€í™˜ ({step2_time:.1f}ì´ˆ)")
    print(f"   Step 3: {len(highlights)}ê°œ í•˜ì´ë¼ì´íŠ¸ ì¶”ì¶œ ({step3_time:.1f}ì´ˆ)")
    print(f"   ì´ ì†Œìš” ì‹œê°„: {total_time:.1f}ì´ˆ")

    print(f"\nğŸ“ ìƒì„±ëœ íŒŒì¼:")
    print(f"   âœ“ output/step1_segments.json")
    print(f"   âœ“ output/step2_transcript.txt")
    print(f"   âœ“ output/step2_transcript.json")
    print(f"   âœ“ output/step2_transcript_with_timestamps.txt")
    print(f"   âœ“ output/step3_highlights.json")

    return {
        'segments': segments,
        'transcript': result,
        'highlights': highlights,
        'timing': {
            'step1': step1_time,
            'step2': step2_time,
            'step3': step3_time,
            'total': total_time
        }
    }


def run_full_pipeline_fast(audio_path: str):
    """
    ì „ì²´ íŒŒì´í”„ë¼ì¸ ë¹ ë¥¸ ì‹¤í–‰ (ì§„í–‰ ìƒí™© ìµœì†Œí™”)

    Args:
        audio_path: ì…ë ¥ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ

    Returns:
        Dict: ì „ì²´ ê²°ê³¼
    """
    from pathlib import Path
    import time

    Path("output").mkdir(parents=True, exist_ok=True)
    total_start = time.time()

    print("ğŸ¬ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ë¹ ë¥¸ ëª¨ë“œ)")
    print("=" * 70)

    # Step 1
    print("â³ [1/3] ì˜¤ë””ì˜¤ ë¶„ì„ ì¤‘...", end=" ", flush=True)
    step1_start = time.time()
    audio_filter = AudioHighlightFilter(verbose=False)
    segments = audio_filter.filter_audio(audio_path)
    step1_time = time.time() - step1_start
    print(f"âœ… ({step1_time:.1f}ì´ˆ) - {len(segments)}ê°œ êµ¬ê°„")

    if not segments:
        print("âŒ í•˜ì´ë¼ì´íŠ¸ êµ¬ê°„ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return None

    # Step 2
    print("â³ [2/3] ìŒì„±-í…ìŠ¤íŠ¸ ë³€í™˜ ì¤‘...", end=" ", flush=True)
    step2_start = time.time()
    transcriber = WhisperTranscriber(model_size="base", device="auto", language="ko", verbose=False)
    result = transcriber.transcribe(audio_path, segments=segments)

    timestamp_text = "\n".join([
        f"[{seg['start']:.1f}s - {seg['end']:.1f}s] {seg['text']}"
        for seg in result['segments']
    ])
    timestamp_path = "output/transcript_timestamps.txt"
    with open(timestamp_path, 'w', encoding='utf-8') as f:
        f.write(timestamp_text)

    step2_time = time.time() - step2_start
    print(f"âœ… ({step2_time:.1f}ì´ˆ) - {len(result['segments'])}ê°œ ì„¸ê·¸ë¨¼íŠ¸")

    # Step 3
    print("â³ [3/3] AI ë¶„ì„ ì¤‘...", end=" ", flush=True)
    step3_start = time.time()
    analyzer = TranscriptAnalyzer(verbose=False)
    highlights = analyzer.analyze_transcript(timestamp_path, "output/highlights.json")
    step3_time = time.time() - step3_start
    print(f"âœ… ({step3_time:.1f}ì´ˆ) - {len(highlights)}ê°œ í•˜ì´ë¼ì´íŠ¸")

    total_time = time.time() - total_start

    print("=" * 70)
    print(f"âœ¨ ì™„ë£Œ! (ì´ {total_time:.1f}ì´ˆ)")
    print(f"   ğŸ“ ì¶œë ¥: output/highlights.json")

    return {
        'segments': segments,
        'transcript': result,
        'highlights': highlights,
        'timing': {'total': total_time}
    }


if __name__ == "__main__":
    import sys

    print("ğŸµ ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸")
    print("=" * 70)
    print()

    # ì…ë ¥ íŒŒì¼ í™•ì¸
    if len(sys.argv) > 1:
        audio_path = sys.argv[1]
    else:
        audio_path = "input/sample_match.mp3"
        print(f"ğŸ’¡ ì‚¬ìš©ë²•: python {Path(__file__).name} <audio_file>")
        print(f"   ê¸°ë³¸ íŒŒì¼ ì‚¬ìš©: {audio_path}\n")

    if not Path(audio_path).exists():
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_path}")
        print(f"\nğŸ’¡ í•´ê²° ë°©ë²•:")
        print(f"   1. 'input/' ë””ë ‰í† ë¦¬ì— ì˜¤ë””ì˜¤ íŒŒì¼ ë„£ê¸°")
        print(f"   2. íŒŒì¼ ê²½ë¡œë¥¼ ì¸ìë¡œ ì „ë‹¬: python {Path(__file__).name} path/to/audio.mp3")
        sys.exit(1)

    # ëª¨ë“œ ì„ íƒ
    print("ì‹¤í–‰ ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”:")
    print("  1. ë‹¨ê³„ë³„ ìƒì„¸ ëª¨ë“œ (ê¶Œì¥) - ê° ë‹¨ê³„ ê²°ê³¼ í™•ì¸")
    print("  2. ë¹ ë¥¸ ì‹¤í–‰ ëª¨ë“œ - ì§„í–‰ ìƒí™©ë§Œ í‘œì‹œ")

    choice = input("\nì„ íƒ (1-2, ê¸°ë³¸ê°’=1): ").strip() or "1"

    if choice == "1":
        result = test_pipeline_step_by_step(audio_path)
    elif choice == "2":
        result = run_full_pipeline_fast(audio_path)
    else:
        print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")
        sys.exit(1)

    if result:
        print("\nğŸ“‹ ìµœì¢… í•˜ì´ë¼ì´íŠ¸ ìš”ì•½:")
        for i, h in enumerate(result['highlights'], 1):
            minutes = int(h['start'] // 60)
            seconds = int(h['start'] % 60)
            print(f"  {i}. [{minutes:02d}:{seconds:02d}] {h['type']}: {h['description']}")

        print("\n" + "=" * 70)
        print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print("=" * 70)
